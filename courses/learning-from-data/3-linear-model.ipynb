{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g2(roots, x):\n",
    "    val = 1\n",
    "    for root in roots:\n",
    "        val *= (x-root)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = (-2,1,-1,5,2)\n",
    "N, x_max = 10, 5\n",
    "x = np.random.rand(N)*x_max\n",
    "noise_sigma = 50\n",
    "noise =np.random.normal(0, noise_sigma, N)\n",
    "y = [g2(roots,xx) for xx in x] + noise\n",
    "points = (x,y)\n",
    "plt.plot(x,y,'o')\n",
    "plt.show()\n",
    "x_original = x"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = (x,y)\n",
    "print(points)\n",
    "np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###  perceptron w/o stoppage\n",
    "\n",
    "# the original line\n",
    "a, b = np.matrix((1, -2)), 3.0\n",
    "x = range(10)\n",
    "# <a,pt> = b\n",
    "# => a_0*x + a_1*y = b\n",
    "# => y = (b - a_0*x) / a_1\n",
    "y = (-b - x * a[0, 0])*1.0 / a[0, 1]\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()\n",
    "\n",
    "# generate random points\n",
    "val_min = min(min(x), min(y))\n",
    "val_max = max(max(x), max(y))\n",
    "val = max(abs(val_min), abs(val_max))\n",
    "n_random = 20\n",
    "data = np.random.rand(2, n_random) * (2 * val) - val\n",
    "vals_pts = a * data + b\n",
    "ixs_pos = np.where(vals_pts >= 0)[1]\n",
    "ixs_neg = np.where(vals_pts < 0)[1]\n",
    "in_pos, in_neg = ixs_pos.shape[0], ixs_neg.shape[0]\n",
    "plt.scatter(data[0, ixs_pos], data[1, ixs_pos], c=['0'] * in_pos)\n",
    "plt.scatter(data[0, ixs_neg], data[1, ixs_neg], c=['1'] * in_neg)\n",
    "\n",
    "\n",
    "## init weight\n",
    "# perceptron learning algo\n",
    "offset = 10\n",
    "# to speed up comparison\n",
    "signs_pts = np.sign(vals_pts)\n",
    "T = 2000\n",
    "w = np.matrix((1, 1, -11))\n",
    "max_p = int(np.max(data))\n",
    "min_p = int(np.min(data))\n",
    "print('max: {0} min: {1}'.format(max_p, min_p))\n",
    "# add 1's as the first entry of each point\n",
    "pts = np.vstack([np.ones(n_random), data])\n",
    "in_discrepancies_all = []\n",
    "in_disc_best, w_best = 1000.0, None\n",
    "for t in range(T):\n",
    "    # show w\n",
    "    x = range(min_p-1, max_p+1)\n",
    "    y = (-w[0,0] - x * w[0,1]) * 1.0 / w[0,2]\n",
    "    #plt.plot(x, y, color = str(t*1.0/T))\n",
    "    \n",
    "    # find the vals\n",
    "    vals_t = w * pts\n",
    "    ixs_discrepancies = np.where(signs_pts != np.sign(vals_t))[1]\n",
    "    in_discrepancies = ixs_discrepancies.shape[0]\n",
    "    in_discrepancies_all.append(in_discrepancies)\n",
    "    \n",
    "    if (in_discrepancies < in_disc_best):\n",
    "        in_disc_best, w_best = in_discrepancies, w\n",
    "    # if there are no discrepencies, the get the fuck lost\n",
    "    if (in_discrepancies == 0):\n",
    "        break\n",
    "    \n",
    "    ix_pt = ixs_discrepancies[0]\n",
    "    # update w\n",
    "    w = w + signs_pts[0, ix_pt] * pts[:, ix_pt]\n",
    "\n",
    "# plot the points\n",
    "plt.scatter(data[0, ixs_pos], data[1, ixs_pos], c=['0'] * in_neg)\n",
    "plt.scatter(data[0, ixs_neg], data[1, ixs_neg], c=['1'] * in_neg)\n",
    "# plot the actual line\n",
    "y_actual = (-b - x * a[0, 0]) * 1.0 / a[0, 1]\n",
    "plt.plot(x, y_actual, color='g')\n",
    "# plot the best line found by perceptron\n",
    "y = (-w_best[0,0] - x * w_best[0,1]) * 1.0 / w_best[0,2]\n",
    "plt.plot(x, y, color='r')\n",
    "\n",
    "plt.axis((val_min-offset,val_max+offset,val_min-offset,val_max+offset))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(in_discrepancies_all)), in_discrepancies_all)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### linear classification using regression - separable\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# basic functions\n",
    "def lm_inner(a, b):\n",
    "    return (a.transpose()*b)[0,0]\n",
    "\n",
    "# generate random points\n",
    "in_pts = 40\n",
    "pts = np.matrix(np.random.rand(in_pts, 2))\n",
    "\n",
    "# find a line passing thro this centroid of the points and the origin\n",
    "# the y-intercept is zero, hence find the slope directly\n",
    "\n",
    "# find and show centroid\n",
    "centroid = pts.mean(0).transpose()\n",
    "\n",
    "print('centroid: \\n{0}'.format(centroid))\n",
    "plt.scatter(centroid[0,0],centroid[1,0], c=[0,0,1] ,s=150)\n",
    "\n",
    "# find line equation\n",
    "# (y-0)/(y1-0) = (x-0)/(x1-0)\n",
    "# => x1*y = y1*x\n",
    "# => <[y1 -x1], [x,y]> = 0\n",
    "a, b = np.matrix((centroid[1,0],-centroid[0,0])).reshape((2,1)), 0\n",
    "print('line equation: \\n{0}'.format(a))\n",
    "\n",
    "# classify the points to find ground truth\n",
    "## todo: find a better way to multiply\n",
    "vals_gt = np.matrix([lm_inner(a, pts[ix,:].transpose()) for ix in range(in_pts)]).transpose()\n",
    "ixs_pos = np.where(vals_gt >= 0)[0]\n",
    "ixs_neg = np.where(vals_gt < 0)[0]\n",
    "plt.scatter(pts[ixs_pos,0],pts[ixs_pos,1],marker='o',s=60, c=[[0,1,0]]*len(ixs_pos),label='+ve')\n",
    "plt.scatter(pts[ixs_neg,0],pts[ixs_neg,1],marker='o',s=60, c=[[1,0,0]]*len(ixs_pos),label='-ve')\n",
    "\n",
    "# show the ground truth line\n",
    "pts_min, pts_max = np.max(pts), np.min(pts)\n",
    "offset = 1\n",
    "line_x = np.linspace(pts_min-offset,pts_max+offset,100)\n",
    "line_y = (-b - line_x * a[0,0])*1.0 / a[1, 0]\n",
    "plt.plot(line_x, line_y, c='b', label='ground truth',linewidth=6)\n",
    "\n",
    "# compute pseudo inverse\n",
    "# Xw = y\n",
    "# Xt*X*w = Xt*y\n",
    "# w = (Xt*X)- * Xt * y\n",
    "X, y = pts, vals_gt\n",
    "w_computed = (X.transpose()*X)**-1 * X.transpose() * y\n",
    "print('computed w: \\n{0}'.format(w_computed))\n",
    "y_w_computed = (-b - line_x * w_computed[0,0])*1.0 / w_computed[1, 0]\n",
    "plt.plot(line_x, y_w_computed, c='y',linewidth=2,label='computed')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath\n",
    "\n",
    "# sample points from a sine function with noise\n",
    "in_pts = 200        # how many points to sample\n",
    "x_min, x_max = 0, +6           # max x values while sampling\n",
    "x_range = float(x_max-x_min)\n",
    "sigma_noise = 1e-10   # sigma of the white noise to add\n",
    "# generate and sort the points\n",
    "x = np.matrix(np.random.rand(in_pts, 1))*x_range+x_min\n",
    "x = np.sort(x,0)\n",
    "# sample from sine\n",
    "y = np.matrix([math.sin(1+xx) for xx in x]).reshape(in_pts,1)\n",
    "# generate noise\n",
    "noise = np.random.normal(0, sigma_noise, (in_pts, 1))\n",
    "data = np.hstack([x, y+noise])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "code_folding": [
     22
    ]
   },
   "outputs": [],
   "source": [
    "# linear regression - non linear transformation using sine wave\n",
    "def lm_poly_fit(x, y, degree):\n",
    "    # compute the transform from x-space to Z-space\n",
    "    X = np.ones_like(x)\n",
    "    for ix_power in range(1,degree+1):\n",
    "        X = np.hstack([X, np.power(x,ix_power)])\n",
    "    # perform the deed of lin regression\n",
    "    w = (X.transpose()*X)**-1 * X.transpose() * y\n",
    "    return w\n",
    "\n",
    "def show_poly_fit(w, color='r',in_pts=100):\n",
    "    # compute the transform from x-space to Z-space\n",
    "    x = np.matrix(np.linspace(x_min, x_max, in_pts)).reshape(in_pts, 1)\n",
    "    degree = w.shape[0]-1\n",
    "    x_aug = np.ones_like(x)\n",
    "    for ix_degree in range(1,degree+1):\n",
    "        x_aug = np.hstack([x_aug, np.power(x, ix_degree)])\n",
    "    # find the hypothesis val\n",
    "    y = x_aug * w\n",
    "    plt.plot(x, y, c=color,linewidth=2,label='degree '+str(degree))\n",
    "    \n",
    "\n",
    "# show original\n",
    "x_sin = np.matrix(np.linspace(x_min,x_max,100)).reshape(100,1)\n",
    "plt.plot(x_sin, np.matrix([math.sin(1+xx) for xx in x_sin]).reshape(x_sin.shape), 'k',label='actual',linewidth=7)\n",
    "#plt.scatter(data[:,0],data[:,1],c='b',marker='o',s=40,label='input')\n",
    "\n",
    "# fit various degree polynomials\n",
    "show_poly_fit(lm_poly_fit(data[:,0], data[:,1], 1),'r',100)\n",
    "show_poly_fit(lm_poly_fit(data[:,0], data[:,1], 2),'c',100)\n",
    "show_poly_fit(lm_poly_fit(data[:,0], data[:,1], 3),'m',100)\n",
    "show_poly_fit(lm_poly_fit(data[:,0], data[:,1], 14),'m',100)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.matrix((1,2))\n",
    "b = np.matrix((3,4))\n",
    "print(np.divide(a,b))\n",
    "s = np.linspace(-5,5,10)\n",
    "print(s.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# lets see what the logistic function does\n",
    "# lower alpha makes it linear, while higher alpha makes it impulse\n",
    "s = np.linspace(-5,5,100).reshape(100,1)\n",
    "def show_logistic(alpha):\n",
    "    x = np.linspace(-10,10)\n",
    "    logistic_numerator = np.power([math.e]*x.shape[0], alpha*x)\n",
    "    # logistic(x) = \\frac{e^{\\alpha*x}}{1 + e^{\\alpha*x}}\n",
    "    plt.plot(x, np.divide(logistic_numerator, logistic_numerator+1))\n",
    "    plt.show()\n",
    "\n",
    "# how logistic function behaves\n",
    "interact(show_logistic, alpha=(0,2,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##### logistic regression\n",
    "## problems faced.\n",
    "## 1. forgot to divide by N and it resulted in OverflowError while computing grad_at_point(in e^(..))\n",
    "## 2. forgot to add the minus sign\n",
    "## 3. the learning rate, eta, was high sometimes => OverflowError\n",
    "## 4. still sometimes, there is overflow error\n",
    "\n",
    "def gradient_at_point(x, y, w):\n",
    "    try:\n",
    "        denominator = math.exp(y * lm_inner(w, x))\n",
    "        return y*x / (1 + denominator)\n",
    "    except OverflowError:\n",
    "        inner_prod1 = lm_inner(w, x)\n",
    "        print('<w,x>: {0}, x: {1}'.format(inner_prod1, x.transpose()))\n",
    "        raise OverflowError\n",
    "\n",
    "def lm_log_regression(x, y, degree, eta = 1e-5, T=20, epsilon=5e-4):\n",
    "    # compute the transform from x-space to Z-space\n",
    "    X = np.ones_like(x)\n",
    "    for ix_power in range(1,degree+1):\n",
    "        X = np.hstack([X, np.power(x,ix_power)])\n",
    "    N, d = x.shape[0], degree+1\n",
    "\n",
    "    # init the weights \n",
    "    w = np.random.normal(scale=3,size=(d,1))\n",
    "    print('initial w: {0}'.format(w.transpose()))\n",
    "    \n",
    "    for t in range(T):\n",
    "        # compute the fucking gradient\n",
    "        gradients = np.zeros_like(w)\n",
    "        # g_t = (-1/N) * \\sum{n=1}{N} gradient_at_point\n",
    "        for ix_data in range(N):\n",
    "            gradients += -gradient_at_point(X[ix_data, :].transpose(), y[ix_data,0], w)\n",
    "    \n",
    "        # set the diretion to move\n",
    "        v_t = -gradients/N\n",
    "        \n",
    "        # update the weights\n",
    "        old_w = w\n",
    "        new_w = w + eta*v_t\n",
    "        \n",
    "        # check for termination\n",
    "        # can use l2 distance or sth else, like change in error(costly)\n",
    "        change_w = np.sum(abs(old_w-new_w))\n",
    "        print('t: {0} change_w: {1} w: {2}'.format(t, change_w, w.transpose()))\n",
    "        if ( change_w < epsilon):\n",
    "            break\n",
    "        w = new_w\n",
    "    return w\n",
    "\n",
    "w = lm_log_regression(data[:,0], data[:, 1], 3)\n",
    "print('\\n\\nfinal w: {0}'.format(w.transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from jupyter_core.paths import jupyter_data_dir, jupyter_path\n",
    "print(jupyter_data_dir())\n",
    "print(jupyter_path())\n",
    "\n",
    "from __future__ import print_function\n",
    "from jupyter_core.paths import jupyter_config_dir, jupyter_config_path\n",
    "print(jupyter_config_dir())\n",
    "print(jupyter_config_path())\n",
    "\n",
    "from jupyter_core.paths import jupyter_config_dir, jupyter_data_dir\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(jupyter_data_dir(), 'extensions'))\n",
    "\n",
    "# c = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.matrix(((3,0),(0,3)))\n",
    "print(a**-1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_display\n",
    "print(centroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.matrix((1, -2)), 3.0\n",
    "x = range(10)\n",
    "# <a,pt> = b\n",
    "# => a_0*x + a_1*y = b\n",
    "# => y = (b - a_0*x) / a_1\n",
    "y = (-b - x * a[0, 0])*1.0 / a[0, 1]\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random as rnd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# required for interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy.polynomial as np_poly\n",
    "\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization  \n",
    "$\n",
    "\\newcommand{\\E}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\V}[1]{\\mathbb{V}\\left[#1\\right]}\n",
    "\\newcommand{\\cov}[1]{\\text{cov} \\sigma\\left[#1\\right]}\n",
    "\\newcommand{\\EXP}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\LN}[1]{\\ln\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\P}{\\mathbb{P}}\n",
    "\\newcommand{\\underl}[1]{\\text{$\\underline{#1}$}}\n",
    "\\newcommand{\\fracone}[1]{\\frac{1}{#1}}\n",
    "\\newcommand{\\half}{\\fracone{2}}\n",
    "\\newcommand{\\Lim}[1]{\\displaystyle \\lim_{#1}}\n",
    "\\newcommand{\\Norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "$\n",
    "\n",
    "$\\newcommand{\\mat}[1]{\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "#1\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "}\n",
    "$\n",
    "\n",
    "$\\newcommand{\\arrthree}[1]{\n",
    "\\begin{array}{rlr}\n",
    "#1\n",
    "\\end{array}\n",
    "}\n",
    "$\n",
    "\n",
    "$\n",
    "\\newcommand{\\D}{\\mathcal{D}}\n",
    "\\newcommand{\\G}{\\mathcal{G}}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\newcommand{\\commentgray}[1]{\\color{gray}{\\text{#1}}}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum, product\n",
    "$\n",
    "\\newcommand{\\sumiN}{\\displaystyle \\sum_{i=1}^{N}}\n",
    "\\newcommand{\\sumjD}{\\displaystyle \\sum_{j=1}^{D}}\n",
    "\\newcommand{\\sumjK}{\\displaystyle \\sum_{j=1}^{K}}\n",
    "\\newcommand{\\sumkK}{\\displaystyle \\sum_{k=1}^{K}}\n",
    "\\newcommand{\\sumkM}{\\displaystyle \\sum_{k=1}^{M}}\n",
    "\\newcommand{\\summN}{\\displaystyle \\sum_{m=1}^{N}}\n",
    "\\newcommand{\\sumnN}{\\displaystyle \\sum_{n=1}^{N}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\prodiN}{\\displaystyle \\prod_{i=1}^{N}}\n",
    "\\newcommand{\\prodjK}{\\displaystyle \\prod_{j=1}^{K}}\n",
    "\\newcommand{\\prodkK}{\\displaystyle \\prod_{k=1}^{K}}\n",
    "\\newcommand{\\prodmN}{\\displaystyle \\prod_{m=1}^{N}}\n",
    "\\newcommand{\\prodnN}{\\displaystyle \\prod_{n=1}^{N}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphabet bold,\n",
    "$\n",
    "\\newcommand{\\Nl}[3]{\\mathcal{N}\\left(#1 \\mid #2, #3\\right)}\n",
    "\\newcommand{\\Nstdx}{\\Nl{\\mathbf{x}}{\\mathbf{\\mu}}{\\Sigma}}\n",
    "\\newcommand{\\ab}{\\mathbf{a}}\n",
    "\\newcommand{\\Ab}{\\mathbf{A}}\n",
    "\\newcommand{\\At}{\\Ab^T}\n",
    "\\newcommand{\\Abjk}{\\Ab_{jk}}\n",
    "\\newcommand{\\bb}{\\mathbf{b}}\n",
    "\\newcommand{\\Bb}{\\mathbf{B}}\n",
    "\\newcommand{\\Bt}{\\Bb^T}\n",
    "\\newcommand{\\Cb}{\\mathbf{C}}\n",
    "\\newcommand{\\Db}{\\mathbf{D}}\n",
    "\\newcommand{\\Hb}{\\mathbf{H}}\n",
    "\\newcommand{\\Lb}{\\mathbf{L}}\n",
    "\\newcommand{\\Lbi}{\\Lb^{-1}}\n",
    "\\newcommand{\\mb}{\\mathbf{m}}\n",
    "\\newcommand{\\Mb}{\\mathbf{M}}\n",
    "\\newcommand{\\Qb}{\\mathbf{Q}}\n",
    "\\newcommand{\\Rb}{\\mathbf{R}}\n",
    "\\newcommand{\\ub}{\\mathbf{u}}\n",
    "\\newcommand{\\Vb}{\\mathbf{V}}\n",
    "\\newcommand{\\Xb}{\\mathbf{X}}\n",
    "\\newcommand{\\Xt}{\\Xb^T}\n",
    "\\newcommand{\\xb}{\\mathbf{x}}\n",
    "\\newcommand{\\xbm}{\\xb_m}\n",
    "\\newcommand{\\xbn}{\\xb_n}\n",
    "\\newcommand{\\xab}{\\mathbf{x_a}}\n",
    "\\newcommand{\\xabt}{\\mathbf{x_a}^T}\n",
    "\\newcommand{\\xbb}{\\mathbf{x_b}}\n",
    "\\newcommand{\\xbbt}{\\mathbf{x_b}^T}\n",
    "\\newcommand{\\yb}{\\mathbf{y}}\n",
    "\\newcommand{\\yt}{\\yb^T}\n",
    "\\newcommand{\\zb}{\\mathbf{z}}\n",
    "\\newcommand{\\zbm}{\\zb_m}\n",
    "\\newcommand{\\zbn}{\\zb_n}\n",
    "\\newcommand{\\zbnp}{\\zb_{n-1}}\n",
    "\\newcommand{\\znk}{\\zb_{nk}}\n",
    "\\newcommand{\\znpj}{\\zb_{n-1,j}}\n",
    "\\newcommand{\\Zb}{\\mathbf{Z}}\n",
    "\\newcommand{\\Ub}{\\mathbf{U}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math bold\n",
    "$\n",
    "\\newcommand{\\chib}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\etab}{\\pmb{\\eta}}\n",
    "\\newcommand{\\etat}{\\eta^T}\n",
    "\\newcommand{\\etabt}{\\etab^T}\n",
    "\\newcommand{\\laa}{\\Lambda_{aa}}\n",
    "\\newcommand{\\laai}{\\Lambda_{aa}^{-1}}\n",
    "\\newcommand{\\lab}{\\Lambda_{ab}}\n",
    "\\newcommand{\\lba}{\\Lambda_{ba}}\n",
    "\\newcommand{\\lbb}{\\Lambda_{bb}}\n",
    "\\newcommand{\\lbbi}{\\Lambda_{bb}^{-1}}\n",
    "\\newcommand{\\li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\mub}{\\pmb{\\mu}}\n",
    "\\newcommand{\\muab}{\\pmb{\\mu}_a}\n",
    "\\newcommand{\\mubb}{\\pmb{\\mu}_b}\n",
    "\\newcommand{\\pib}{\\pmb{\\pi}}\n",
    "\\newcommand{\\saa}{\\Sigma_{aa}}\n",
    "\\newcommand{\\sab}{\\Sigma_{ab}}\n",
    "\\newcommand{\\sba}{\\Sigma_{ba}}\n",
    "\\newcommand{\\sbb}{\\Sigma_{bb}}\n",
    "\\newcommand{\\thetab}{\\pmb{\\theta}}\n",
    "\\newcommand{\\thetat}{\\thetab^T}\n",
    "\\newcommand{\\thetabh}{\\hat{\\thetab}}\n",
    "\\newcommand{\\thetaold}{\\thetab^{\\text{old}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aliases for distributions\n",
    "$\\newcommand{\\multivarcoeff}{\\frac{1}{(2\\pi)^{D/2}}\n",
    "\\frac{1}{\\left| \\mathbf{\\Sigma}\\right|^{1/2}}}$\n",
    "$\\newcommand{\\multivarexp}[2]\n",
    "{\n",
    "\\left\\{\n",
    " -\\frac{1}{2} \n",
    " {#1}^T \n",
    " #2\n",
    " {#1}\n",
    "\\right\\}\n",
    "}$\n",
    "$\\newcommand{\\multivarexpx}[1]{\\multivarexp{#1}{\\Sigma^{-1}}}$\n",
    "$\\newcommand{\\multivarexpstd}{\\multivarexpx{(\\xb-\\mub)}}$\n",
    "$\\newcommand{\\gam}{\\operatorname{Gam}}$\n",
    "$\n",
    "\\newcommand{\\sumkMl}{\\sum_{k=1}^{M-1}}\n",
    "\\newcommand{\\sumjMl}{\\sum_{j=1}^{M-1}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... Lecture 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "======\n",
    "\n",
    "1. how bayes rule is derived\n",
    "1. applying bayes rule to simple examples\n",
    "1. applying bayesian learning to linear models\n",
    "1. mechanics of conjugate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Diagnoses\n",
    "=====================\n",
    "\n",
    "* doctor has bad news and good news\n",
    "* bad news is that you tested positive for a serious disease and that the test is 99% accurate\n",
    "* the good news is that this is a rare disease, striking only 1 in 10,000 people\n",
    "* what are the chances that you actually have the disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Rule\n",
    "==========\n",
    "\n",
    "Bayes rule enables us to reverse probabilities\n",
    "$$\n",
    "p(\\Ab \\mid \\Bb) = \n",
    "\\frac{p(\\Bb \\mid \\Ab) ~p(\\Ab)}{p(\\Bb)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Alison Gopnik: What do babies think? | TED Talk | TED.com](https://www.ted.com/talks/alison_gopnik_what_do_babies_think)  \n",
    "\n",
    "[Joshua Tenenbaum PhD '99 - The Brain as Computer](https://www.youtube.com/watch?v=k8ppSA0FJwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\overbrace{p(AB)}^{\\text{joint}} &= \n",
    "\\overbrace{p(B \\mid A)}^{\\text{conditional}}\n",
    "~\\overbrace{p(A)}^{\\text{marginal}}\n",
    "& \\commentgray{chain rule}\n",
    "\\\\ &=\n",
    "\\underbrace{p(A \\mid B)}_{\\text{conditional}}\n",
    "~\\underbrace{p(B)}_{\\text{marginal}}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\int p(AB) ~dA ~dB &= 1\n",
    "\\\\\n",
    "\\int p(A \\mid B) ~dA &= 1\n",
    "\\\\\n",
    "\\int p(A) ~dA &= 1\n",
    "\\\\\n",
    "p(A) &= \\int p(AB) ~dB & \\commentgray{marginalization}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In $p(A \\mid B)$, B is given, observed.  \n",
    "  * example: A - temperature, B - country  \n",
    "* in spain, the temperature dist is one way  \n",
    "* in france, it might completely different\n",
    "* for each country, the histograms are normalized  \n",
    "* then any country, the hist. sums to one\n",
    "* anything on the right side of the bar has been observed and there is no uncertainty about it. there is no need to use probability to know things we know. prob is used for things that we don't know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning and Bayesian inference\n",
    "================================\n",
    "\n",
    "$$\n",
    "p(h \\mid d) = \n",
    "\\frac{p(d \\mid h) ~p(h)}{p(d)}\n",
    "=\n",
    "\\frac{p(d \\mid h) ~p(h)}{\\displaystyle \\sum_{h^{\\prime} \\in \\mathcal{H}} \n",
    "\\underbrace{p(d \\mid h^{\\prime}) ~p(h)^{\\prime}}_{p(d, h^{\\prime})}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sum in the denominator is very hard to find. it results in a combinatorial explosion. in continuous case, it becomes intractable or hard to solve analytically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Diagnoses\n",
    "=====================\n",
    "\n",
    "The test is 99% accurate: $p(t=1 \\mid d=1) = 0.99$ and $p(t=0 \\mid d=0) = 0.99$, where **T** denotes test and **D** denotes disease.\n",
    "\n",
    "The disease affects 1 in 10,000: $p(d=1) = 0.0001$\n",
    "\n",
    "$$\n",
    "\\arrthree{\n",
    "p(d=1 \\mid t=1) &= \n",
    "\\frac{p(t=1 \\mid d=1) p(d=1)}\n",
    "{p(t=1 \\mid d=0) p(d=0) + p(t=1 \\mid d=1) p(d=1)}\n",
    "\\\\ &=\n",
    "\\frac{0.99 * 0.0001}{(1-0.99)*(1-0.0001) + 0.99*0.0001}\n",
    "\\\\ &=\n",
    "0.0098\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009803921568627442"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.99*0.0001)/((1-0.99)*(1-0.0001)+0.99*0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech recognition\n",
    "==================\n",
    "\n",
    "$$\n",
    "\\underbrace{p(\\text{words} \\mid \\text{sound})}_{\\text{final beliefs}} \\propto\n",
    "\\underbrace{p(\\text{sound} \\mid \\text{words})}_{\\text{data likelihood}} ~\\underbrace{p(\\text{words})}_{\\text{prior language model}}\n",
    "$$\n",
    "\n",
    "* data likelihood: mixture of Gaussians\n",
    "* prior language model: unigrams\n",
    "* these two form HMM\n",
    "\n",
    "Recognize speech $\\Leftrightarrow$ Wreck a nice beach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian learning for model parameters\n",
    "======================================\n",
    "\n",
    "1. Given n data, $\\D = x_{1:n} = \\left\\{ x_1, x_2, \\cdots, x_n \\right\\}$, write down the **likelihood**\n",
    "$$\n",
    "p(\\D \\mid \\thetab)\n",
    "$$\n",
    "1. specify a **prior**: $p(\\thetab)$\n",
    "  * uncertainty over parameters\n",
    "  * bayesians do not believe in the concept of true $\\thetab$ in finite data cases\n",
    "  * in ML, $\\thetab$ is not a RV. rather, the randomness is in the data\n",
    "  * prior: models initial beliefs\n",
    "1. compute the **posterior**\n",
    "$$\n",
    "p(\\thetab \\mid \\D) = \n",
    "\\frac{p(\\D \\mid \\thetab) ~p(\\thetab)}{p(\\D)}\n",
    "\\propto p(\\D \\mid \\thetab) ~p(\\thetab)\n",
    "$$\n",
    "$$\n",
    "p(\\D) = \\int p(\\D \\mid \\thetab) p(\\thetab) ~d\\thetab = \\int p(\\D,\\thetab) ~p\\thetab\n",
    "$$\n",
    "\n",
    "this is aposteriori inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian view\n",
    "--------------\n",
    "\n",
    "what is the prob that this dude will take up a job in a different university?\n",
    "1. 0.01\n",
    "1. 0.03\n",
    "1. 0.4\n",
    "1. 0.5\n",
    "\n",
    "the idiotic students answer this coz they are \n",
    "1. fuckers\n",
    "1. have different beliefs, ie, different values for $\\thetab$\n",
    "\n",
    "the prior is introduced to capture this precise uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequentist view\n",
    "----------------\n",
    "\n",
    "take a coin and toss in 100 times and observe the #times the coin turns up heads. thats the frequentist view. you look at the frequencies and say what the probability should be. as n inf, the count of a particular event tends to the true expectation [LoLN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian linear regression\n",
    "==========================\n",
    "\n",
    "* the likelihood is a Gaussian, $\\mathcal{N}(\\yb \\mid \\Xb \\thetab, \\sigma^2 \\I_N)$\n",
    "* the conjugate prior is also a Gaussian, which we will denote by $p(\\thetab) = \\mathcal{N}(\\thetab \\mid \\thetab_0, \\Vb_0)$\n",
    "* using bayes rule for Gaussians, the posterior is given by\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\thetab \\mid \\Xb, \\yb, \\sigma^2) &\\propto\n",
    "\\mathcal{N}(\\thetab \\mid \\thetab_0, \\Vb_0)\n",
    "~\\mathcal{N}(\\yb \\mid \\Xb \\thetab, \\sigma^2 \\I_N)\n",
    "\\\\ &=\n",
    "\\mathcal{N}(\\thetab \\mid \\thetab_N, \\Vb_N)\n",
    "\\\\\n",
    "\\thetab_n &=\n",
    "\\Vb_N ~\\Vb_0^{-1} ~\\thetab_0\n",
    "+ \n",
    "\\fracone{\\sigma^2} ~\\Vb_N ~\\Xt ~\\yb\n",
    "\\\\\n",
    "\\Vb_N^{-1} &=\n",
    "\\Vb_0^{-1} ~+ ~\\fracone{\\sigma^2} \\Xt \\Xb\n",
    "}\n",
    "$$\n",
    "\n",
    "this is called conjugate analysis. prior-gaussian => posterior-gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior tends to be flat, since there is a cloud of uncertainty surrounding it.  \n",
    "the likelihood is relatively more peaked than the prior.  \n",
    "the posterior is the middle ground between the two.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of coming with a best model and spend a lotta time computing it, it is better to go with a simpler model which is easy to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume $\\sigma^2$ is known\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "p(\\thetab \\mid \\Xb, \\yb, \\sigma^2)\n",
    "& \\propto\n",
    "p(\\yb \\mid \\Xb, \\thetab, \\sigma^2) ~p(\\thetab)\n",
    "\\\\ &=\n",
    "\\EXP{-\\half (\\yb - \\Xb \\thetab)^T (\\sigma^2 \\I)^{-1} (\\yb - \\Xb \\thetab)}\n",
    "\\\\ & \n",
    "\\EXP{-\\half (\\thetab - \\thetab_0)^T \\Vb_0^{-1} (\\thetab - \\thetab_0)}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look only the exponent\n",
    "\n",
    "$$\n",
    "\\yt (\\sigma^2 \\I)^{-1} \\yb\n",
    "- \\color{magenta}{2 \\yt (\\sigma^2 \\I)^{-1} \\Xb \\thetab}\n",
    "+ \\color{maroon}{\\thetat \\Xt (\\sigma^2 \\I)^{-1} \\Xb \\thetab}\n",
    "+ \\color{maroon}{\\thetat \\Vb_0^{-1} \\thetab}\n",
    "- \\color{magenta}{2 \\thetat \\Vb_0^{-1} \\thetab}\n",
    "+ \\thetab_0^T \\Vb_o^{-1} \\thetab_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouping the quadratic and linear terms in $\\thetab$\n",
    "\n",
    "$$\n",
    "=\\text{const}\n",
    "+ \\thetat\n",
    "  \\overbrace{\\color{maroon}{\\left(\\Xt (\\sigma^2 \\I)^{-1} \\Xb + \\Vb_0^{-1}\\right)}}^{\\text{call this} \\Vb_N^{-1}}\n",
    "  \\thetab\n",
    "- 2 \n",
    "  \\left(\n",
    "    \\color{magenta}{\\yt (\\sigma^2 \\I)^{-1} \\Xb + \\thetab_0^T \\Vb_0^{-1}}\n",
    "  \\right)\n",
    "  \\thetab\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shortening by $\\Vb_N^{-1}$\n",
    "\n",
    "$$\n",
    "= \\text{const}\n",
    "+ \\thetat \\Vb_N^{-1} \\thetab\n",
    "- 2\n",
    "  \\left(\n",
    "    \\frac{\\yt \\Xb}{\\sigma^2}\n",
    "    + \\thetab_0^T \\Vb_0^{-1}\n",
    "  \\right)\n",
    "  \\thetab\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding and subtracting $2 \\thetab_N^T \\Vb_N^{-1} \\thetab$, we get...\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "= \\text{const}\n",
    "+ \\thetat \\Vb_N^{-1} \\thetab\n",
    "- 2 \\thetab_N^T \\Vb_N^{-1} \\thetab\n",
    "+ 2 \\thetab_N^T \\Vb_N^{-1} \\thetab\n",
    "- 2\n",
    "  \\left(\n",
    "    \\frac{\\yt \\Xb}{\\sigma^2}\n",
    "    + \\thetab_0^T \\Vb_0^{-1}\n",
    "  \\right)\n",
    "  \\thetab\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally it becomes ...\n",
    "\n",
    "\\begin{array}{rlr}\n",
    " \\text{const} \n",
    " + (\\thetab - \\thetab_N)^T \\Vb_N^{-1} (\\thetab - \\thetab_N)\n",
    " + 2\n",
    "   \\left[\n",
    "     \\thetab_N^T \\Vb_N^{-1}\n",
    "     - \\frac{\\yb^T \\Xb}{\\sigma^2}\n",
    "     - \\thetab_0^T \\Vb_0^{-1}\n",
    "   \\right]\n",
    "   \\thetab\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\thetab_N^T \\Vb_N^{-1}\n",
    "- \\frac{\\yb^T \\Xb}{\\sigma^2}\n",
    "- \\thetab_0^T \\Vb_0^{-1}\n",
    "= 0\n",
    "$\n",
    "when\n",
    "$\n",
    "\\thetab_N\n",
    "=\n",
    "\\Vb_N\n",
    "\\left[\n",
    "  \\Vb_0^{-1} \\thetab_0\n",
    "  + \\frac{\\Xt \\yb}{\\sigma^2}\n",
    "\\right]\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and when this happens, we have\n",
    "$$\n",
    "p(\\thetab \\mid \\Xb, \\yb, \\sigma^2)\n",
    "\\propto\n",
    "\\EXP{-\\half (\\thetab - \\thetab_N)^T \\Vb_N^{-1} (\\thetab - \\thetab_N)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the definition of the multivariate Gaussian, we have\n",
    "$$\n",
    "\\int \\EXP{-\\half (\\thetab - \\thetab_N)^T \\Vb_N^{-1} (\\thetab - \\thetab_N)} ~d\\thetab = \n",
    "\\left|\n",
    " 2 \\pi \\Vb_N\n",
    "\\right|^{1/2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\therefore ~~~\n",
    "p(\\thetab \\mid \\Xb, \\yb, \\sigma^2)\n",
    "=\n",
    "\\left| 2\\pi\\sigma^2 \\right|^{-1/2}\n",
    "\\EXP{-\\half (\\thetab - \\thetab_N)^T \\Vb_N^{-1} (\\thetab - \\thetab_N)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special case\n",
    "--------------\n",
    "\n",
    "Consider the special case where $\\thetab_0 = 0$ and $\\Vb_0 = \\tau_0^2 \\I_d$, which is a spherical Gaussian prior.  \n",
    "Then the posterior mean reduces to\n",
    "\\begin{array}{rlr}\n",
    "\\thetab_n &=\n",
    "\\fracone{\\sigma^2} \\Vb_N \\Xt \\yb\n",
    "\\\\ &=\n",
    "\\fracone{\\sigma^2}\n",
    "\\left(\n",
    "  \\fracone{\\tau_0^2} \\I_d\n",
    "  + \\fracone{\\sigma^2} \\Xt \\Xb\n",
    "\\right)^{-1} \\Xt \\yb\n",
    "\\\\ &=\n",
    "\\left(\n",
    "  \\lambda \\I_d + \\Xt \\Xb\n",
    "\\right)^{-1}\n",
    "\\Xt \\yb\n",
    "\\end{array}\n",
    "\n",
    "where we have defined $\\lambda = \\frac{\\sigma^2}{\\tau_0^2}$.\n",
    "\n",
    "we have therefore recovered ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the prior is very flat, which is essentially saying that we donno anything about the parameters, we have $\\Vb_0$ very high.    \n",
    "That is, $\\tau_0^2 \\rightarrow \\infty$.    \n",
    "that is $\\lambda \\rightarrow 0$.  \n",
    "hence, $\\thetab_N = (\\Xt \\Xb)^{-1} \\Xt \\yb$  \n",
    "hence, we end up with ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem for Gaussians (from KPM)\n",
    "=================================\n",
    "\n",
    "From chapter 4\n",
    "\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\xb) &= \\mathcal{N}(\\xb \\mid \\mub_x, \\Sigma_x) \\\\\n",
    "p(\\yb \\mid \\xb) &=\n",
    "\\mathcal{N}(\\yb \\mid \\Ab \\xb + \\bb, \\Sigma_y)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\xb \\mid \\yb) &=\n",
    "\\mathcal{N}(\\xb \\mid \\mub_{\\xb \\mid \\yb}, \\Sigma_{\\xb \\mid \\yb})\n",
    "\\\\\n",
    "\\Sigma_{\\xb \\mid \\yb}^{-1} &=\n",
    "\\Sigma_x^{-1} + \\At \\Sigma_y^{-1} \\Ab\n",
    "\\\\\n",
    "\\mub_{\\xb \\mid \\yb} &=\n",
    "\\Sigma_{\\xb \\mid \\yb}\n",
    "\\left\\{\n",
    "  \\At \\Sigma_y^{-1} (\\yb - \\bb)\n",
    "  + \\Sigma_x^{-1} \\mub_x\n",
    "\\right\\}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution  \n",
    "\n",
    "$$\n",
    "p(\\yb) = \\mathcal{N}(\n",
    "  \\yb \\mid \\Ab \\mub_x + \\bb,\n",
    "  \\Sigma_y + \\Ab \\Sigma_X \\At\n",
    ")\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian versus ML plugin prediction\n",
    "====================================\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "\\text{Posterior Mean} \\thetab_n\n",
    "&=\n",
    "\\left(\n",
    "  \\lambda \\I_d + \\Xt \\Xb\n",
    "\\right)^{-1} \\Xt \\yb\n",
    "\\\\\n",
    "\\text{Posterior Variance} \\Vb_n\n",
    "&=\n",
    "\\sigma^2\n",
    "\\left(\n",
    "  \\lambda \\I_d + \\Xt \\Xb\n",
    "\\right)^{-1}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To predict, Bayesians marginalize over the posterior.\n",
    "* Let $x_*$ be a new input.\n",
    "* The prediction, given the training data $\\D = (\\Xb, \\yb)$, is:\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\yb \\mid x_*, \\D, \\sigma^2)\n",
    "&=\n",
    "\\int\n",
    "\\mathcal{N}(\\yb \\mid x_*^T \\thetab, \\sigma^2)\n",
    "~\\mathcal{N}(\\thetab \\mid \\thetab_N, \\Vb_N)\n",
    "~d\\thetab\n",
    "\\\\ &=\n",
    "\\mathcal{N}(x_*^T \\thetab_N, \\sigma^2 + x_*^T \\Vb_N x_*)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this is equivalent to saying that we are marginalizing out the parameters, as bayesians would say.  \n",
    "* it would also mean that instead of computing a scalar value y, what we are doing is convolving the first Gaussian with the posterior.  \n",
    "* that it, each value of y predicted by the first term is weighted by the posterior of the parameters governing the first term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the ML plugin predictor is:\n",
    "$$\n",
    "p(\\yb \\mid x_*, \\D, \\sigma^2)\n",
    "=\n",
    "\\mathcal{N}(\\yb \\mid x_*^T \\thetab_{ML}, \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What these losers are doing is to convolve a gaussian with a delta function. that is\n",
    "$$\n",
    "p(y \\mid x_*, \\D, \\sigma^2) = \n",
    "\\int \\mathcal{N}(\n",
    "y \\mid x_*^T \\thetab, \\sigma^2)\n",
    "~\\delta_{\\hat{\\thetab}_{\\text{ML}}}(\\thetab) \n",
    "~d\\thetab\n",
    "=\n",
    "\\mathcal{N}(\\yb \\mid x_*^T \\thetab_{ML}, \\sigma^2)\n",
    "$$\n",
    "\n",
    "It should be noted that the convolution with a dirac delta function is equivalent to choosing the value of $\\thetab$, which in this case is $\\hat{\\thetab}_{\\text{ML}}$. This is coz the frequentists assume that there is only one theta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on the other hands, bayesians say that there are infinite number of thetas and you have to weigh each prediction by its posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, $\\hat{\\thetab}_{\\text{ML}}$ and $\\thetab_N$ tend to be more or less the same. The functional forms of the predictions for these two paradigms are more or less the same except for the variance term in the bayesian paradigm having an additional term $x_*^T \\Vb_N x_*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of this is in case of ML, the uncertainty or confidence is the same in the entire input space, not differentiating between regions in which we have sampled the data and in which we haven't.\n",
    "\n",
    "the bayesian estimate on the other hand, produces estimates with higher confidence in the regions where we have samples and lower confidence in regions of the input space where we haven't observed any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can i prove this assertion from the functional form of $\\Vb_N$?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two intepretations of regression\n",
    "---------------\n",
    "\n",
    "* Linear:\n",
    "    $\\hat{y} = wx$\n",
    "* Bayesian (MLE & MAP):\n",
    "    $y \\sim N(wx, \\sigma^2)$\n",
    "    $\\textrm{argmax}_w p(D|w)$\n",
    "    \n",
    "*Review slides on Linear Regression*\n",
    "\n",
    "In regression, we're always given X. Thus, given X, what's the Y?\n",
    "   \n",
    "* MAP:\n",
    "    $\\textrm{argmax}_w \\prod_{i=1}^n p(y_i | w, x_i) p(w)$\n",
    "* MLE:\n",
    "    $\\textrm{argmax}_w \\prod_{i=1}^n p(y_i | w, x_i)$ ... or something\n",
    "    \n",
    "* Estimating means for normal distribution:  \n",
    "  We have a prior: that $y_i \\sim N(\\mu, \\sigma^2)$  \n",
    "  We add a prior: $w \\sim N(0, \\gamma^2)$  \n",
    "  See the slides for how to use these priors  \n",
    "\n",
    "- Constant Term in Linear Regression  \n",
    "  Coding up things in Matlab, you generally need to add in a constant \n",
    "  term... Something to watch for \n",
    "\n",
    "Linear Regression with Varying Noise  \n",
    "-----------------------\n",
    "Different noise at each observation: Heteroscedasticicity  \n",
    "With every observation, different noise:  \n",
    "    in the real world, the noise on more extreme measurements is often \n",
    "    greater\n",
    "  \n",
    "$y_i \\sim N(wx_i, \\sigma_i^2)$  <- note how sigma changes with $i$\n",
    "  \n",
    "Sometimes we know something about the noise, and then we can use\n",
    "different sigmas at each point, assume independence among noise,\n",
    "then plugging in eqn for Gaussian and simplifying.  \n",
    "  \n",
    "This is called Weighted Regression:  \n",
    "  $\\textrm{argmin}_w \\sum_{i = 1}^R (y_i - wx_i)/sigma_i^2$\n",
    "  \t  \n",
    "  i.e., you weigh noisy measurements less\n",
    "\n",
    "Non-linear Regression \n",
    "-----------------\n",
    "Suppose you know that y is related to a function of x in such a way \n",
    "that the predicted values [lost slide]...  \n",
    "    $y_i ~ N(\\sqrt{w + x_i}, \\sigma^2)$\n",
    "\n",
    "MLE: $\\textrm{argmin}_w \\sum (y_i - \\sqrt{w + x_i}_)^2$  \n",
    "    Then use non-linear optimization techniques, of which many are \n",
    "    available\n",
    "\n",
    "Polynomial Regression\n",
    "----------------------\n",
    "  $y = a + bx^2$  \n",
    "Is this linear or nonlinear regression?  \n",
    "    It is _linear_\n",
    "\n",
    "We make a new variable:\n",
    "    \n",
    "    z = [1 x_1^2 \n",
    "         1 x_2^2\n",
    "         ...\n",
    "         1 x_n^2 ]\n",
    "    \n",
    "Now:\n",
    "    $\\hat{y} = zw$ and it is linear (linear in weights)  \n",
    "    \n",
    "* $w = w \\sin(x)$ <- linear estimation  \n",
    "      * $\\sin(x)$ is a transformed feature, but still a feature  \n",
    "      * $w$ is still linear  \n",
    "        \n",
    "$y = \\sin(wx)$ <- nonlinear estimation  \n",
    "\n",
    "\n",
    " Radial Basis Functions (RBF)\n",
    "--------------------------\n",
    "  Often you have some really non-linear relationship between X and\n",
    "  Y. Can you do some transformation on these to make the relationship\n",
    "  linear? \n",
    "\n",
    "  Let us choose a set of points on x:  $z_1 \\dots z_k$\n",
    "  For each point we will create a Gaussian distribution\n",
    "  $z_j = e^{\\frac{||x - \\mu_j||}{\\sigma^2}}$\n",
    "\n",
    "  For every $x$, generate a bunch of $Z$s where the $Z$s near $X$ will be\n",
    "  weighted heavily, and the $Z$s far from $X$ will be zero\n",
    "\n",
    "  One adjustable parameter in this situation: the kernel width, or\n",
    "  $\\sigma$. If the kernel width is really big, everything comes out. If\n",
    "  it is really narrow, then only very close things have an effect\n",
    "\n",
    "  Now the Xs are correlated, so we generally use a Ridge Regression\n",
    "  (MAP)\n",
    "\n",
    "  This method is LOESS\n",
    "\n",
    "Later: the use of kernels in regression"
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

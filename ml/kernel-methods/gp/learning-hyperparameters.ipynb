{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random as rnd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# required for interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy.polynomial as np_poly\n",
    "\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pprint import pprint\n",
    "import functools as ft\n",
    "\n",
    "from scipy import optimize as sp_optimize\n",
    "from scipy.spatial.distance import pdist as sp_dist\n",
    "from scipy.spatial.distance import squareform as sp_squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization\n",
    "$\n",
    "\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\Bracket}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\cases}[1]{\\begin{cases}#1\\end{cases}}\n",
    "\\newcommand{\\cov}[1]{\\text{cov} \\sigma\\left[#1\\right]}\n",
    "\\newcommand{\\diff}[2]{\\frac{d #1}{d #2}}\n",
    "\\newcommand{\\difftwo}[2]{\\frac{d^2 #1}{d {#2}^2}}\n",
    "\\newcommand{\\diffn}[2]{{#1}^{\\prime}(#2)}\n",
    "\\newcommand{\\E}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\expb}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\EXP}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\frachalf}[1]{\\frac{#1}{2}~}\n",
    "\\newcommand{\\fracone}[1]{\\frac{1}{#1}~}\n",
    "\\newcommand{\\fracrec}[1]{\\frac{1}{#1}~}\n",
    "\\newcommand{\\half}{\\fracone{2}}\n",
    "\\newcommand{\\H}[1]{\\mathbb{H}\\left[#1\\right]}\n",
    "\\newcommand{\\Int}[2]{\\displaystyle \\int_{#1}^{#2}~}\n",
    "\\newcommand{\\intinfinf}{\\Int{-\\infty}{\\infty}}\n",
    "\\newcommand{\\inv}[1]{#1^{-1}}\n",
    "\\newcommand{\\invp}[1]{\\left({#1}\\right)^{-1}}\n",
    "\\newcommand{\\KL}[2]{\\text{KL}\\left(#1 \\Vert #2\\right)}\n",
    "\\newcommand{\\Lim}[1]{\\displaystyle \\lim_{#1}}\n",
    "\\newcommand{\\Ln}[1]{\\ln \\left\\(#1\\right\\)}\n",
    "\\newcommand{\\Lnb}[1]{\\ln \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\Mod}[1]{\\left|#1\\right|}\n",
    "\\newcommand{\\Norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\newcommand{\\Normsqr}[1]{\\Norm{#1}^2}\n",
    "\\newcommand{\\map}[1]{#1_{\\text{MAP}}}\n",
    "\\newcommand{\\ml}[1]{#1_{\\text{ML}}}\n",
    "\\newcommand{\\MI}[1]{\\mathcal{I}\\left(#1\\right)}\n",
    "\\newcommand{\\P}{\\mathbb{P}}\n",
    "\\newcommand{\\Paran}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\Partial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\sqrbrkt}[1]{\\Bracket{#1}^2}\n",
    "\\newcommand{\\sqrbrc}[1]{\\Brace{#1}^2}\n",
    "\\newcommand{\\trace}[1]{\\text{Tr}\\left( #1 \\right)}\n",
    "\\newcommand{\\traceb}[1]{\\text{Tr}\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\underl}[1]{\\text{$\\underline{#1}$}}\n",
    "\\newcommand{\\V}[1]{\\mathbb{V}\\left[#1\\right]}\n",
    "$\n",
    "$\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\mat}[1]{ \\left[ \\begin{matrix} #1 \\end{matrix} \\right] }\n",
    "\\newcommand{\\matp}[1]{ \\left( \\begin{matrix} #1 \\end{matrix} \\right)}\n",
    "\\newcommand{\\mats}[1]{ \\begin{matrix}#1\\end{matrix} }\n",
    "\\newcommand{\\arrthree}[1]{\n",
    "\\begin{array}{rlr} #1 \\end{array}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\Ca}{\\mathcal{C}}\n",
    "\\newcommand{\\Caone}{\\Ca_1}\n",
    "\\newcommand{\\Catwo}{\\Ca_2}\n",
    "\\newcommand{\\Cak}{\\Ca_k}\n",
    "\\newcommand{\\D}{\\mathcal{D}}\n",
    "\\newcommand{\\G}{\\mathcal{G}}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\L}{\\mathcal{L}}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\Ra}{\\mathcal{R}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\commentgray}[1]{\\color{gray}{\\text{#1}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum, product\n",
    "$\n",
    "\\newcommand{\\sumi}{\\displaystyle \\sum_i}\n",
    "\\newcommand{\\sumiD}{\\displaystyle \\sum_{i=1}^{D}}\n",
    "\\newcommand{\\sumiL}{\\displaystyle \\sum_{i=1}^{L}}\n",
    "\\newcommand{\\sumiN}{\\displaystyle \\sum_{i=1}^{N}}\n",
    "\\newcommand{\\sumjD}{\\displaystyle \\sum_{j=1}^{D}}\n",
    "\\newcommand{\\sumjK}{\\displaystyle \\sum_{j=1}^{K}}\n",
    "\\newcommand{\\sumjMl}{\\sum_{j=1}^{M-1}}\n",
    "\\newcommand{\\sumkK}{\\displaystyle \\sum_{k=1}^{K}}\n",
    "\\newcommand{\\sumkM}{\\displaystyle \\sum_{k=1}^{M}}\n",
    "\\newcommand{\\sumkMl}{\\sum_{k=1}^{M-1}}\n",
    "\\newcommand{\\summN}{\\displaystyle \\sum_{m=1}^{N}}\n",
    "\\newcommand{\\sumnN}{\\displaystyle \\sum_{n=1}^{N}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\prodi}{\\displaystyle \\prod_i}\n",
    "\\newcommand{\\prodiD}{\\displaystyle \\prod_{i=1}^{D}}\n",
    "\\newcommand{\\prodiL}{\\displaystyle \\prod_{i=1}^{L}}\n",
    "\\newcommand{\\prodiN}{\\displaystyle \\prod_{i=1}^{N}}\n",
    "\\newcommand{\\prodjK}{\\displaystyle \\prod_{j=1}^{K}}\n",
    "\\newcommand{\\prodkK}{\\displaystyle \\prod_{k=1}^{K}}\n",
    "\\newcommand{\\prodmN}{\\displaystyle \\prod_{m=1}^{N}}\n",
    "\\newcommand{\\prodnN}{\\displaystyle \\prod_{n=1}^{N}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphabet shortcuts\n",
    "$\n",
    "\\newcommand{\\ab}{\\mathbf{a}}\n",
    "\\newcommand{\\at}{\\ab^T}\n",
    "\\newcommand{\\Ab}{\\mathbf{A}}\n",
    "\\newcommand{\\At}{\\Ab^T}\n",
    "\\newcommand{\\Ai}{\\inv{\\Ab}}\n",
    "\\newcommand{\\Abjk}{\\Ab_{jk}}\n",
    "\\newcommand{\\bb}{\\mathbf{b}}\n",
    "\\newcommand{\\bt}{\\bb^T}\n",
    "\\newcommand{\\Bb}{\\mathbf{B}}\n",
    "\\newcommand{\\Bt}{\\Bb^T}\n",
    "\\newcommand{\\Cb}{\\mathbf{C}}\n",
    "\\newcommand{\\Cn}{\\Cb_{N}}\n",
    "\\newcommand{\\Db}{\\mathbf{D}}\n",
    "\\newcommand{\\fb}{\\mathbf{f}}\n",
    "\\newcommand{\\fp}{f^{\\prime}}\n",
    "\\newcommand{\\Hb}{\\mathbf{H}}\n",
    "\\newcommand{\\hx}{h(\\xb)}\n",
    "\\newcommand{\\Jb}{\\mathbf{J}}\n",
    "\\newcommand{\\kb}{\\mathbf{k}}\n",
    "\\newcommand{\\kt}{\\kb^T}\n",
    "\\newcommand{\\Kb}{\\mathbf{K}}\n",
    "\\newcommand{\\Lb}{\\mathbf{L}}\n",
    "\\newcommand{\\Lt}{\\Lb^T}\n",
    "\\newcommand{\\Lbi}{\\Lb^{-1}}\n",
    "\\newcommand{\\mb}{\\mathbf{m}}\n",
    "\\newcommand{\\mt}{\\mb^T}\n",
    "\\newcommand{\\mbn}{\\mb_N}\n",
    "\\newcommand{\\mbnt}{\\mbn^T}\n",
    "\\newcommand{\\mbN}{\\mb_N}\n",
    "\\newcommand{\\mbNt}{\\mbn^T}\n",
    "\\newcommand{\\Mb}{\\mathbf{M}}\n",
    "\\newcommand{\\Qb}{\\mathbf{Q}}\n",
    "\\newcommand{\\Rb}{\\mathbf{R}}\n",
    "\\newcommand{\\sb}{\\mathbf{s}}\n",
    "\\newcommand{\\Sb}{\\mathbf{S}}\n",
    "\\newcommand{\\tb}{\\mathbf{t}}\n",
    "\\newcommand{\\tbnn}{\\tb_{N}}\n",
    "\\newcommand{\\tbnp}{\\tb_{N+1}}\n",
    "\\newcommand{\\tt}{\\tb^T}\n",
    "\\newcommand{\\Tb}{\\mathbf{T}}\n",
    "\\newcommand{\\Tt}{\\Tb^T}\n",
    "\\newcommand{\\ub}{\\mathbf{u}}\n",
    "\\newcommand{\\Ub}{\\mathbf{U}}\n",
    "\\newcommand{\\Ut}{\\Ub^T}\n",
    "\\newcommand{\\vb}{\\mathbf{v}}\n",
    "\\newcommand{\\Vb}{\\mathbf{V}}\n",
    "\\newcommand{\\wb}{\\mathbf{w}}\n",
    "\\newcommand{\\wnr}[1]{\\wb^{(\\text{#1})}}\n",
    "\\newcommand{\\wt}{\\wb^T}\n",
    "\\newcommand{\\Wb}{\\mathbf{W}}\n",
    "\\newcommand{\\Wt}{\\Wb^T}\n",
    "\\newcommand{\\Wtilde}{\\widetilde{\\Wb}}\n",
    "\\newcommand{\\Wtildet}{\\Wtilde^T}\n",
    "\\newcommand{\\Xb}{\\mathbf{X}}\n",
    "\\newcommand{\\Xt}{\\Xb^T}\n",
    "\\newcommand{\\Xtilde}{\\widetilde{\\Xb}}\n",
    "\\newcommand{\\Xtildet}{\\Xtilde^T}\n",
    "\\newcommand{\\xb}{\\mathbf{x}}\n",
    "\\newcommand{\\xt}{\\xb^T}\n",
    "\\newcommand{\\xtilde}{\\widetilde{\\xb}}\n",
    "\\newcommand{\\xtilden}{\\xtilde_n}\n",
    "\\newcommand{\\xtildent}{\\xtilden^T}\n",
    "\\newcommand{\\xp}{x^{\\prime}}\n",
    "\\newcommand{\\xbp}{\\xb^{\\prime}}\n",
    "\\newcommand{\\xbm}{\\xb_m}\n",
    "\\newcommand{\\xbn}{\\xb_n}\n",
    "\\newcommand{\\xbnp}{\\xb_{N+1}}\n",
    "\\newcommand{\\xab}{\\mathbf{x_a}}\n",
    "\\newcommand{\\xabt}{\\mathbf{x_a}^T}\n",
    "\\newcommand{\\xbb}{\\mathbf{x_b}}\n",
    "\\newcommand{\\xbbt}{\\mathbf{x_b}^T}\n",
    "\\newcommand{\\yb}{\\mathbf{y}}\n",
    "\\newcommand{\\yt}{\\yb^T}\n",
    "\\newcommand{\\yx}{y(\\xb)}\n",
    "\\newcommand{\\zb}{\\mathbf{z}}\n",
    "\\newcommand{\\zt}{\\zb^T}\n",
    "\\newcommand{\\zbm}{\\zb_m}\n",
    "\\newcommand{\\zbn}{\\zb_n}\n",
    "\\newcommand{\\zbnp}{\\zb_{n-1}}\n",
    "\\newcommand{\\znk}{\\zb_{nk}}\n",
    "\\newcommand{\\znpj}{\\zb_{n-1,j}}\n",
    "\\newcommand{\\Zb}{\\mathbf{Z}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math shortcuts\n",
    "$\n",
    "\\newcommand{\\chib}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\etab}{\\pmb{\\eta}}\n",
    "\\newcommand{\\etat}{\\eta^T}\n",
    "\\newcommand{\\etabt}{\\etab^T}\n",
    "\\newcommand{\\Lambdab}{\\pmb{\\Lambda}}\n",
    "\\newcommand{\\laa}{\\Lambda_{aa}}\n",
    "\\newcommand{\\laai}{\\Lambda_{aa}^{-1}}\n",
    "\\newcommand{\\lab}{\\Lambda_{ab}}\n",
    "\\newcommand{\\lba}{\\Lambda_{ba}}\n",
    "\\newcommand{\\lbb}{\\Lambda_{bb}}\n",
    "\\newcommand{\\lbbi}{\\Lambda_{bb}^{-1}}\n",
    "\\newcommand{\\li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\Li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\mub}{\\pmb{\\mu}}\n",
    "\\newcommand{\\mut}{\\mub^T}\n",
    "\\newcommand{\\muab}{\\pmb{\\mu}_a}\n",
    "\\newcommand{\\mubb}{\\pmb{\\mu}_b}\n",
    "\\newcommand{\\Phib}{\\pmb{\\Phi}}\n",
    "\\newcommand{\\Phibt}{\\Phib^T}\n",
    "\\newcommand{\\pib}{\\pmb{\\pi}}\n",
    "\\newcommand{\\sigmasqr}{\\sigma^2}\n",
    "\\newcommand{\\saa}{\\Sigma_{aa}}\n",
    "\\newcommand{\\sab}{\\Sigma_{ab}}\n",
    "\\newcommand{\\sba}{\\Sigma_{ba}}\n",
    "\\newcommand{\\sbb}{\\Sigma_{bb}}\n",
    "\\newcommand{\\Sigmai}{\\inv{\\Sigma}}\n",
    "\\newcommand{\\thetab}{\\pmb{\\theta}}\n",
    "\\newcommand{\\thetat}{\\thetab^T}\n",
    "\\newcommand{\\thetabh}{\\hat{\\thetab}}\n",
    "\\newcommand{\\thetaold}{\\thetab^{\\text{old}}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\zerob}{\\pmb{0}}\n",
    "\\newcommand{\\ed}{\\mathbb{E}_{\\D}}\n",
    "\\newcommand{\\edyx}{\\ed\\left[y(\\xb ; \\D)\\right]}\n",
    "\\newcommand{\\dx}{~dx}\n",
    "\\newcommand{\\dxb}{~d\\xb}\n",
    "\\newcommand{\\pxdxb}{p(\\xb) \\dxb}\n",
    "\\newcommand{\\dwb}{~d\\wb}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aliases for distributions\n",
    "$\\newcommand{\\multivarcoeff}{\\frac{1}{(2\\pi)^{D/2}}\n",
    "\\frac{1}{\\left| \\mathbf{\\Sigma}\\right|^{1/2}}}$\n",
    "$\\newcommand{\\multivarexp}[2]\n",
    "{\n",
    "\\left\\{\n",
    " -\\frac{1}{2} \n",
    " {#1}^T \n",
    " #2\n",
    " {#1}\n",
    "\\right\\}\n",
    "}$\n",
    "$\\newcommand{\\multivarexpx}[1]{\\multivarexp{#1}{\\Sigma^{-1}}}$\n",
    "$\\newcommand{\\multivarexpstd}{\\multivarexpx{(\\xb-\\mub)}}$\n",
    "$\\newcommand{\\gam}{\\operatorname{Gam}}$\n",
    "$\n",
    "\\newcommand{\\Nl}[3]{\\mathcal{N}\\left(#1 \\mid #2, #3\\right)}\n",
    "\\newcommand{\\Nstdx}{\\Nl{\\mathbf{x}}{\\mathbf{\\mu}}{\\Sigma}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than fixing the covariance, the parameters for the covariance can be inferred from the data.\n",
    "\n",
    "These parameters govern things like\n",
    "* length-scale of the correlations\n",
    "* precision of the noise\n",
    "\n",
    "and as such correspond to the hyperparametrs of the standard parametric model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to evaluate the likelihood function $p(\\tb \\mid \\thetab)$ where $\\thetab$ denotes the hyperparameters of the GP model.  \n",
    "\n",
    "simplest approach is to make a point estimate of $\\thetab$ by maximizing the log likelihood function.\n",
    "\n",
    "since $\\thetab$ represents the set of hyperparameters of the regressoin problem, this is analogous to type 2 ML for linear regression.\n",
    "\n",
    "Maximizatio of the log likelihood can be done using efficient gradient-based optimization algos such as conjugate gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mean of the marginal is \n",
    "$\\Nl{t}{\\Ab \\mub + \\bb}{\\Lbi + \\Ab \\Li \\At}$, we have\n",
    "\n",
    "$$\n",
    "p(\\tb) = \\Nl{\\tb}{\\zerob}{\\inv{\\beta}\\I_N + \\Kb}\n",
    "= \\Nl{\\tb}{\\zerob}{\\Cb}\n",
    "$$\n",
    "\n",
    "where the covariance is\n",
    "$$\n",
    "\\Cb(\\xbn, \\xbm) = \\inv{\\beta} \\delta_{nm} + \\kappa(\\xbn, \\xbm)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the log likelihood is then\n",
    "$$\n",
    "\\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\ln \\Mod{\\Cn}\n",
    "-\\half \\tt \\inv{\\Cn} \\tb\n",
    "-\\frachalf{N} \\ln(2\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the first term is the complexity penalty term\n",
    "* The second term a negative quadratic, and plays the role of a data-fit measure\n",
    "* The third term is a log normalization term, independent of the data, and not very interesting\n",
    "\n",
    "from \\citeme{Gaussian Processes in Machine Learning - Carl Edward Rasmussen}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because ln p(t | **θ**) will in general be a nonconvex function, it can have multiple maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember\n",
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{x} \\Mod{\\Ab} &= \\trace{ \\inv{\\Ab} \\Partial{\\Ab}{x}}\n",
    "\\\\\n",
    "\\Partial{}{x} \\inv{\\Ab} &= -\\inv{\\Ab} \\Partial{\\Ab}{x} \\inv{\\Ab}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{\\xb} (\\Ab \\Ai)\n",
    "&=\n",
    "\\Partial{\\Ab}{\\xb}\\Ai  + \\Ab \\Partial{\\Ai}{\\xb} = 0\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus\n",
    "$$\n",
    "\\Partial{}{\\theta_i} \\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\trace{\\inv{\\Cn} \\Partial{\\Cn}{\\theta_i}}\n",
    "+ \\half \\tt \\inv{\\Cn} \\Partial{\\Cn}{\\theta_i} \\inv{\\Cn} \\tb\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $\\ln p(\\tb \\mid \\thetab)$ will in general be a nonconvex function, it can have multiple maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to introduce a prior over **θ** and to maximize the log posterior using gradient-based methods. In a fully Bayesian treatment, we need to evaluate marginals over **θ** weighted by the product of the prior p(**θ**) and the likelihood function p(**t**|**θ**). In general, however, exact marginalization will be intractable, and we\n",
    "must resort to approximations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seek the minimum value of the expression\n",
    "$au^2 + buv + cv^2 + du + ev + f$ for given values of the parameters and an initial guess (u, v) = (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (2, 3, 7, 8, 9, 10)  # parameter values\n",
    "\n",
    "def f(x, *args):\n",
    "    u, v = x\n",
    "    a, b, c, d, e, f = args\n",
    "    return a*u**2 + b*u*v + c*v**2 + d*u + e*v + f\n",
    "\n",
    "def gradf(x, *args):\n",
    "    u, v = x\n",
    "    a, b, c, d, e, f = args\n",
    "    gu = 2*a*u + b*v + d\t # u-component of the gradient\n",
    "    gv = b*u + 2*c*v + e\t # v-component of the gradient\n",
    "    return np.asarray((gu, gv))\n",
    "\n",
    "x0 = np.asarray((0, 0))\t # Initial guess.\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "res1 = optimize.fmin_cg(f, x0, fprime=gradf, args=args)\n",
    "\n",
    "print('res1 = ', res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\ln \\Mod{\\Cn}\n",
    "-\\half \\tt \\inv{\\Cn} \\tb\n",
    "-\\frachalf{N} \\ln(2\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{\\theta_i} \\ln p(\\tb \\mid \\thetab)\n",
    "&=\n",
    "-\\half \\trace{\\inv{\\Cn} \\Partial{\\Cn}{\\theta_i}}\n",
    "+ \\half \\tt \\inv{\\Cn} \\Partial{\\Cn}{\\theta_i} \\inv{\\Cn} \\tb\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the rbf kernel with just the length-scale parameter $\\sigma$\n",
    "\n",
    "$$\n",
    "\\Cb_{n,m} = \\kappa(\\xbn, \\xbm) =\n",
    "\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{\\sigma} \\Cb_{n,m}\n",
    "&=\n",
    "\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2\\sigma^2}}\n",
    " ~\\frac{\\Norm{\\xbn-\\xbm}^2}{\\sigma^3}\n",
    "\\\\ &\n",
    "=\n",
    "\\Bracket{\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2}}}^{(1/\\sigma^2)}\n",
    "~\\Norm{\\xbn-\\xbm}^2 ~\\fracrec{\\sigma^3}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "A_{n,m} &= \\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2}} \\\\\n",
    "B_{n,m} &= \\Norm{\\xbn - \\xbm}^2 \\\\\n",
    "Ci &= \\inv{\\Cn}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: construct f-partial and pass it to CG"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sin():\n",
    "    thetas = np.linspace(0,2*math.pi,100)\n",
    "    plt.plot(thetas, np.sin(thetas), 'g')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_samples(in_pts, betai=1.0, uniform=False):\n",
    "    if uniform:\n",
    "        x = np.linspace(0,2*math.pi, in_pts).reshape(-1,1)\n",
    "    else:\n",
    "        x = np.random.rand(in_pts).reshape(-1,1)*2*math.pi\n",
    "    if betai==0.0:\n",
    "        y_noise = np.zeros_like(x)\n",
    "    else:\n",
    "        y_noise = np.random.normal(0, betai, size=(in_pts,1))\n",
    "    y = np.sin(x) + y_noise\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_1(x1, y1, sigma):\n",
    "    exponent = -np.square(x1-y1)/(2.*sigma**2)\n",
    "    return np.exp(exponent)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gp_covar(xgt, tgt, betai, sigma):\n",
    "    n = xgt.shape[0]\n",
    "    pairwise_dists = squareform(pdist(xgt, 'euclidean'))\n",
    "    K = np.exp(-pairwise_dists ** 2 / sigma ** 2) + 1e-6*np.eye(n)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(xt, tt, cni, betai, x, sigma):\n",
    "    n = cni.shape[0]\n",
    "    k = np.array([kernel_1(xt[ix], x, sigma) for ix in range(n)])\n",
    "    k = k.reshape(-1,1)\n",
    "    mean1 = k.T @ cni @ tt\n",
    "    c = kernel_1(x, x, sigma) + betai\n",
    "    covar1 = c - k.T @ cni @ k\n",
    "    return [mean1, covar1]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions2(xt, tt, cni, betai, x, sigma):\n",
    "    n = cni.shape[0]\n",
    "    k_star = kernel_1(xt, x.T, sigma)\n",
    "    #k = np.array([kernel_1(xt[ix], x, sigma) for ix in range(n)])\n",
    "    #k = k.reshape(-1,1)\n",
    "    mean1 = k_star.T @ cni @ tt\n",
    "    c = get_gp_covar + betai\n",
    "    covar1 = c - k_star.T @ cni @ k_star\n",
    "    return [mean1, covar1]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing correctness of computing \\Cb\n",
    "A = np.array([[0,1],[2,3]])\n",
    "print('A\\n', A)\n",
    "print(np.exp(-A)**(1/2.))\n",
    "print([math.e**(-aa/2.) for aa in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\ln \\Mod{\\Cn}\n",
    "-\\half \\tt \\inv{\\Cn} \\tb\n",
    "-\\frachalf{N} \\ln(2\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the rbf kernel with just the length-scale parameter $\\sigma$\n",
    "\n",
    "$$\n",
    "\\Cb_{n,m} = \\kappa(\\xbn, \\xbm) =\n",
    "\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CG is for minimizing and we have to maximize the likelihood.  \n",
    "hence we have to take negative log likelihood, which explains the negative sign in the return value"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(sigma, *args):\n",
    "    A, B, t, N = args\n",
    "    C = A**(1./(sigma**2)) + np.eye(N)*1e-2\n",
    "    #eigen_vals = np.linalg.eigvals(C)\n",
    "    Ci = np.linalg.inv(C)\n",
    "    Cd = np.linalg.det(C)\n",
    "    if Cd < 1e-200:\n",
    "        minC, maxC = np.min(C.ravel()), np.max(C.ravel())\n",
    "        print('det is two low: ', Cd, ' [',minC,',',maxC,']')\n",
    "    term1 = -0.5 * math.log(Cd)\n",
    "    term2 = -0.5 * t.T @ Ci @ t \n",
    "    term3 = -N/2. * math.log(2*math.pi)\n",
    "    return -(term1 + term2 + term3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sigma_min(x, t, N):\n",
    "    B = np.square(x - x.T)\n",
    "    A = np.exp( - B/2.)\n",
    "    res1 = sp_optimize.fmin_cg(f, (1.), args=(A, B, t, N))\n",
    "    #print('sigma optimal = ', res1[0])\n",
    "    return abs(res1[0])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covar(x, mu, varr):\n",
    "    n = x.shape[0]\n",
    "    for ix in range(n):\n",
    "        xx = x[ix]\n",
    "        m, v = mu[ix], varr[ix]\n",
    "        plt.plot((xx,xx),(m-v,m+v), color=(248/255., 163/255., 211/255.))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cholesky(cn):\n",
    "    u, s, v = np.linalg.svd(cn)\n",
    "    #print(s.shape)\n",
    "    if isinstance(s[0], complex):\n",
    "        print('complex machie')\n",
    "    else:\n",
    "        print('not complex')\n",
    "    if(np.all(s > 0)):\n",
    "        print('positive definite')\n",
    "    else:\n",
    "        print('not positive definite')\n",
    "    L = u @ np.diag(np.sqrt(s))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_posterior(xgt, tgt, cni, \n",
    "                           betai, x_test, sigma,\n",
    "                           plot_posteriors, plot_mean):\n",
    "    arr_mean, arr_covar = get_predictions2(xgt, tgt, cni, betai, x_test, sigma)\n",
    "    if plot_mean:\n",
    "        plot_sin()\n",
    "        plt.plot(xgt, tgt, '.b')\n",
    "        plt.plot(x_test, arr_mean)\n",
    "        plt.show()\n",
    "    if plot_posteriors:\n",
    "        n_curves, n = 10, x_test.shape[0]\n",
    "        arr_mean = np.array(arr_mean)\n",
    "        #tmp = np.random.multivariate_normal(arr_mean.ravel(),\n",
    "        #                                    cov=arr_covar,\n",
    "        #                                   size=(10)).T\n",
    "        L = my_cholesky(arr_covar)\n",
    "        f_posterior = np.dot(L, np.random.normal(size=(n,n_curves)))\n",
    "        plt.plot(x_test, f_posterior)\n",
    "        plt.plot(xgt, tgt, '.b')\n",
    "        #plt.plot(x_test, arr_mean, 'r', linewidth=3)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp_reg(in_pts = 20, betai=0.2, test_max= 2*math.pi,\n",
    "                uniform=False, plot_posteriors=True, plot_mean=True):\n",
    "    xgt, tgt = draw_samples(in_pts, betai, uniform)\n",
    "    sigma = find_sigma_min(xgt, tgt, in_pts)\n",
    "    print('sigma-min: ', sigma, ' ', type(sigma))\n",
    "    cn = get_gp_covar(xgt, tgt, betai, sigma)\n",
    "    eigen_vals = np.linalg.eigvals(cn)\n",
    "    tmp_product = 1\n",
    "    [tmp_product*eigen_val for eigen_val in eigen_vals]\n",
    "    #print('eigen values: {0}:{1}, {2}:{3}, p: {4}'.format(np.min(eigen_vals), type(np.min(eigen_vals)),\n",
    "    #                                                      np.max(eigen_vals), type(np.max(eigen_vals)),\n",
    "    #                                                      tmp_product))\n",
    "    #print(np.all(eigen_vals > 0))\n",
    "    #print(type(cn))\n",
    "    cni = np.linalg.inv(cn)\n",
    "\n",
    "    x_test = np.linspace(0,test_max,30)\n",
    "    plot_samples_posterior(xgt, tgt, cni, betai, \n",
    "                           x_test, sigma, plot_posteriors, plot_mean)\n",
    "\n",
    "interact(plot_gp_reg,\n",
    "         in_pts=(10, 100, 5),\n",
    "         betai=(0,5.0,0.1),\n",
    "         test_max=(math.pi, 4*math.pi, 0.1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp_reg(in_pts = 88, betai=0.2, test_max= 2*math.pi,\n",
    "                uniform=True, plot_posteriors=True, plot_mean=False):\n",
    "    xgt, tgt = draw_samples(in_pts, betai, uniform)\n",
    "    sigma = find_sigma_min(xgt, tgt, in_pts)\n",
    "    cn = get_gp_covar(xgt, tgt, betai, sigma)\n",
    "    cn = cn + 1e-6*np.eye(in_pts)\n",
    "    cni = np.linalg.inv(cn)\n",
    "    x_test = np.linspace(0,test_max,100)\n",
    "    t_test = np.array([get_predictions(xgt, tgt, cni, betai, xx, sigma) \n",
    "                       for xx in x_test])\n",
    "    t_test = t_test.reshape(-1, 2)\n",
    "    plot_sin()\n",
    "    plt.plot(xgt, tgt, '.b')\n",
    "    plt.plot(x_test, t_test[:,0])\n",
    "    plot_covar(x_test, t_test[:,0], t_test[:,1])\n",
    "    plt.show()\n",
    "    \n",
    "    plot_samples_posterior(xgt, tgt, cni, betai, x_test, sigma)\n",
    "\n",
    "interact(plot_gp_reg,\n",
    "         in_pts=(2, 100, 1),\n",
    "         betai=(0,5.0,0.1),\n",
    "         test_max=(math.pi, 4*math.pi, 0.1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sexy part is that the uncertainty is quite high where we haven't data and is low in the neighborhood of data.  \n",
    "thats brings us to the second problem, why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2(\\xbnp) = c - \\kt \\inv{\\Cn} \\kb\n",
    "$$\n",
    "\n",
    "The second term is very negative in the regions of data since $\\kt \\inv{\\Cn} \\kb$ is high, which brings down the uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.random.multivariate_normal)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=7\n",
    "x,t = draw_samples(N)\n",
    "A = np.square(x - x.T)\n",
    "B = np.exp(-A/2.)\n",
    "print('det(exp(A)): ',np.linalg.det(B))\n",
    "print('exp(tr(A))', math.e**(A.trace()))\n",
    "print('tr(A)', A.trace())\n",
    "print('log(det(exp(A)))', math.log(np.linalg.det(B)))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=35\n",
    "x,t = draw_samples(N)\n",
    "B = np.square(x - x.T)\n",
    "A = np.exp( - B/2.)\n",
    "res1 = sp_optimize.fmin_cg(f, (1.), args=(A, B, t, N))\n",
    "print('res1 = ', res1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as sp_la\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import random as rnd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# required for interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy.polynomial as np_poly\n",
    "\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pprint import pprint\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization\n",
    "$\n",
    "\\newcommand{\\E}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\V}[1]{\\mathbb{V}\\left[#1\\right]}\n",
    "\\newcommand{\\H}[1]{\\mathbb{H}\\left[#1\\right]}\n",
    "\\newcommand{\\cov}[1]{\\text{cov} \\sigma\\left[#1\\right]}\n",
    "\\newcommand{\\EXP}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\LN}[1]{\\ln\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\P}{\\mathbb{P}}\n",
    "\\newcommand{\\underl}[1]{\\text{$\\underline{#1}$}}\n",
    "\\newcommand{\\fracone}[1]{\\frac{1}{#1}}\n",
    "\\newcommand{\\half}{\\fracone{2}}\n",
    "\\newcommand{\\Lim}[1]{\\displaystyle \\lim_{#1}}\n",
    "\\newcommand{\\Norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\newcommand{\\inv}[1]{#1^{-1}}\n",
    "\\newcommand{\\invp}[1]{\\left({#1}\\right)^{-1}}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\newcommand{\\ml}[1]{#1_{\\text{ML}}}\n",
    "\\newcommand{\\Partial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\KL}[2]{\\text{KL}\\left(#1 \\Vert #2\\right)}\n",
    "\\newcommand{\\MI}[1]{\\mathcal{I}\\left(#1\\right)}\n",
    "\\newcommand{\\Ln}[1]{\\ln \\left\\(#1\\right\\)}\n",
    "\\newcommand{\\Lnb}[1]{\\ln \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\Mod}[1]{\\left|#1\\right|}\n",
    "\\newcommand{\\Bracket}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\trace}[1]{\\text{Tr}\\left( #1 \\right)}\n",
    "\\newcommand{\\sqrbrkt}[1]{\\Bracket{#1}^2}\n",
    "\\newcommand{\\sqrbrc}[1]{\\Brace{#1}^2}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\mat}[1]{ \\left[ \\begin{matrix} #1 \\end{matrix} \\right] }\n",
    "\\newcommand{\\matp}[1]{ \\left( \\begin{matrix} #1 \\end{matrix} \\right)}\n",
    "\\newcommand{\\mats}[1]{ \\begin{matrix}#1\\end{matrix} }\n",
    "\\newcommand{\\arrthree}[1]{\n",
    "\\begin{array}{rlr} #1 \\end{array}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\Ca}{\\mathcal{C}}\n",
    "\\newcommand{\\D}{\\mathcal{D}}\n",
    "\\newcommand{\\G}{\\mathcal{G}}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\L}{\\mathcal{L}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\Ra}{\\mathcal{R}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\commentgray}[1]{\\color{gray}{\\text{#1}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum, product\n",
    "$\n",
    "\\newcommand{\\sumiD}{\\displaystyle \\sum_{i=1}^{D}}\n",
    "\\newcommand{\\sumiN}{\\displaystyle \\sum_{i=1}^{N}}\n",
    "\\newcommand{\\sumjD}{\\displaystyle \\sum_{j=1}^{D}}\n",
    "\\newcommand{\\sumjK}{\\displaystyle \\sum_{j=1}^{K}}\n",
    "\\newcommand{\\sumjMl}{\\sum_{j=1}^{M-1}}\n",
    "\\newcommand{\\sumkK}{\\displaystyle \\sum_{k=1}^{K}}\n",
    "\\newcommand{\\sumkM}{\\displaystyle \\sum_{k=1}^{M}}\n",
    "\\newcommand{\\sumkMl}{\\sum_{k=1}^{M-1}}\n",
    "\\newcommand{\\summN}{\\displaystyle \\sum_{m=1}^{N}}\n",
    "\\newcommand{\\sumnN}{\\displaystyle \\sum_{n=1}^{N}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\prodiD}{\\displaystyle \\prod_{i=1}^{D}}\n",
    "\\newcommand{\\prodiN}{\\displaystyle \\prod_{i=1}^{N}}\n",
    "\\newcommand{\\prodjK}{\\displaystyle \\prod_{j=1}^{K}}\n",
    "\\newcommand{\\prodkK}{\\displaystyle \\prod_{k=1}^{K}}\n",
    "\\newcommand{\\prodmN}{\\displaystyle \\prod_{m=1}^{N}}\n",
    "\\newcommand{\\prodnN}{\\displaystyle \\prod_{n=1}^{N}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphabet shortcuts\n",
    "$\n",
    "\\newcommand{\\ab}{\\mathbf{a}}\n",
    "\\newcommand{\\Ab}{\\mathbf{A}}\n",
    "\\newcommand{\\At}{\\Ab^T}\n",
    "\\newcommand{\\Ai}{\\inv{\\Ab}}\n",
    "\\newcommand{\\Abjk}{\\Ab_{jk}}\n",
    "\\newcommand{\\bb}{\\mathbf{b}}\n",
    "\\newcommand{\\bt}{\\bb^T}\n",
    "\\newcommand{\\Bb}{\\mathbf{B}}\n",
    "\\newcommand{\\Bt}{\\Bb^T}\n",
    "\\newcommand{\\Cb}{\\mathbf{C}}\n",
    "\\newcommand{\\Db}{\\mathbf{D}}\n",
    "\\newcommand{\\fb}{\\mathbf{f}}\n",
    "\\newcommand{\\fp}{f^{\\prime}}\n",
    "\\newcommand{\\Hb}{\\mathbf{H}}\n",
    "\\newcommand{\\hx}{h(\\xb)}\n",
    "\\newcommand{\\Jb}{\\mathbf{J}}\n",
    "\\newcommand{\\Kb}{\\mathbf{K}}\n",
    "\\newcommand{\\Lb}{\\mathbf{L}}\n",
    "\\newcommand{\\Lt}{\\Lb^T}\n",
    "\\newcommand{\\Lbi}{\\Lb^{-1}}\n",
    "\\newcommand{\\mb}{\\mathbf{m}}\n",
    "\\newcommand{\\mt}{\\mb^T}\n",
    "\\newcommand{\\Mb}{\\mathbf{M}}\n",
    "\\newcommand{\\Qb}{\\mathbf{Q}}\n",
    "\\newcommand{\\Rb}{\\mathbf{R}}\n",
    "\\newcommand{\\Sb}{\\mathbf{S}}\n",
    "\\newcommand{\\tb}{\\mathbf{t}}\n",
    "\\newcommand{\\ub}{\\mathbf{u}}\n",
    "\\newcommand{\\Ub}{\\mathbf{U}}\n",
    "\\newcommand{\\Ut}{\\Ub^T}\n",
    "\\newcommand{\\vb}{\\mathbf{v}}\n",
    "\\newcommand{\\Vb}{\\mathbf{V}}\n",
    "\\newcommand{\\wb}{\\mathbf{w}}\n",
    "\\newcommand{\\wt}{\\wb^T}\n",
    "\\newcommand{\\Wb}{\\mathbf{W}}\n",
    "\\newcommand{\\Xb}{\\mathbf{X}}\n",
    "\\newcommand{\\Xt}{\\Xb^T}\n",
    "\\newcommand{\\xb}{\\mathbf{x}}\n",
    "\\newcommand{\\xt}{\\xb^T}\n",
    "\\newcommand{\\xp}{x^{\\prime}}\n",
    "\\newcommand{\\xbp}{\\xb^{\\prime}}\n",
    "\\newcommand{\\xbm}{\\xb_m}\n",
    "\\newcommand{\\xbn}{\\xb_n}\n",
    "\\newcommand{\\xab}{\\mathbf{x_a}}\n",
    "\\newcommand{\\xabt}{\\mathbf{x_a}^T}\n",
    "\\newcommand{\\xbb}{\\mathbf{x_b}}\n",
    "\\newcommand{\\xbbt}{\\mathbf{x_b}^T}\n",
    "\\newcommand{\\yb}{\\mathbf{y}}\n",
    "\\newcommand{\\yt}{\\yb^T}\n",
    "\\newcommand{\\yx}{y(\\xb)}\n",
    "\\newcommand{\\zb}{\\mathbf{z}}\n",
    "\\newcommand{\\zt}{\\zb^T}\n",
    "\\newcommand{\\zbm}{\\zb_m}\n",
    "\\newcommand{\\zbn}{\\zb_n}\n",
    "\\newcommand{\\zbnp}{\\zb_{n-1}}\n",
    "\\newcommand{\\znk}{\\zb_{nk}}\n",
    "\\newcommand{\\znpj}{\\zb_{n-1,j}}\n",
    "\\newcommand{\\Zb}{\\mathbf{Z}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math shortcuts\n",
    "$\n",
    "\\newcommand{\\chib}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\etab}{\\pmb{\\eta}}\n",
    "\\newcommand{\\etat}{\\eta^T}\n",
    "\\newcommand{\\etabt}{\\etab^T}\n",
    "\\newcommand{\\Lambdab}{\\pmb{\\Lambda}}\n",
    "\\newcommand{\\laa}{\\Lambda_{aa}}\n",
    "\\newcommand{\\laai}{\\Lambda_{aa}^{-1}}\n",
    "\\newcommand{\\lab}{\\Lambda_{ab}}\n",
    "\\newcommand{\\lba}{\\Lambda_{ba}}\n",
    "\\newcommand{\\lbb}{\\Lambda_{bb}}\n",
    "\\newcommand{\\lbbi}{\\Lambda_{bb}^{-1}}\n",
    "\\newcommand{\\li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\Li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\mub}{\\pmb{\\mu}}\n",
    "\\newcommand{\\mut}{\\mub^T}\n",
    "\\newcommand{\\muab}{\\pmb{\\mu}_a}\n",
    "\\newcommand{\\mubb}{\\pmb{\\mu}_b}\n",
    "\\newcommand{\\Phib}{\\pmb{\\Phi}}\n",
    "\\newcommand{\\Phibt}{\\Phib^T}\n",
    "\\newcommand{\\pib}{\\pmb{\\pi}}\n",
    "\\newcommand{\\sigmasqr}{\\sigma^2}\n",
    "\\newcommand{\\saa}{\\Sigma_{aa}}\n",
    "\\newcommand{\\sab}{\\Sigma_{ab}}\n",
    "\\newcommand{\\sba}{\\Sigma_{ba}}\n",
    "\\newcommand{\\sbb}{\\Sigma_{bb}}\n",
    "\\newcommand{\\thetab}{\\pmb{\\theta}}\n",
    "\\newcommand{\\thetat}{\\thetab^T}\n",
    "\\newcommand{\\thetabh}{\\hat{\\thetab}}\n",
    "\\newcommand{\\thetaold}{\\thetab^{\\text{old}}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\zerob}{\\pmb{0}}\n",
    "\\newcommand{\\ed}{\\mathbb{E}_{\\D}}\n",
    "\\newcommand{\\edyx}{\\ed\\left[y(\\xb ; \\D)\\right]}\n",
    "\\newcommand{\\dx}{~dx}\n",
    "\\newcommand{\\dxb}{~d\\xb}\n",
    "\\newcommand{\\pxdxb}{p(\\xb) \\dxb}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aliases for distributions\n",
    "$\\newcommand{\\multivarcoeff}{\\frac{1}{(2\\pi)^{D/2}}\n",
    "\\frac{1}{\\left| \\mathbf{\\Sigma}\\right|^{1/2}}}$\n",
    "$\\newcommand{\\multivarexp}[2]\n",
    "{\n",
    "\\left\\{\n",
    " -\\frac{1}{2} \n",
    " {#1}^T \n",
    " #2\n",
    " {#1}\n",
    "\\right\\}\n",
    "}$\n",
    "$\\newcommand{\\multivarexpx}[1]{\\multivarexp{#1}{\\Sigma^{-1}}}$\n",
    "$\\newcommand{\\multivarexpstd}{\\multivarexpx{(\\xb-\\mub)}}$\n",
    "$\\newcommand{\\gam}{\\operatorname{Gam}}$\n",
    "$\n",
    "\\newcommand{\\Nl}[3]{\\mathcal{N}\\left(#1 \\mid #2, #3\\right)}\n",
    "\\newcommand{\\Nstdx}{\\Nl{\\mathbf{x}}{\\mathbf{\\mu}}{\\Sigma}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<style>\"\\\n",
    "    \"div.cell{\"\\\n",
    "        \"width:50%;\"\\\n",
    "        \"margin-left:25%;\"\\\n",
    "        \"margin-right:auto;\"\\\n",
    "    \"}\"\\\n",
    "\"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From <a href='#GaussianIidLikelihood'>Likelihood</a> given by\n",
    "$$\n",
    "p(\\tb \\mid \\wb, \\beta) =\n",
    "\\left(\n",
    "  \\dfrac{\\beta}{2\\pi}\n",
    "\\right)^{N/2}\n",
    "\\EXP{\n",
    "  -\\dfrac{\\beta}{2}\n",
    "  \\sumnN \\left( t_n - \\wt \\phi\\left(\\xb_n\\right) \\right)^2\n",
    "}\n",
    "= \\Nl{\\tb}{\\Phibt \\wb}{\\beta \\I}\n",
    "$$\n",
    "\n",
    "Since the likelihood is exponential of quadratic function of **w**, the prior is a Gaussian given by\n",
    "$$ p(\\wb) = \\Nl{\\wb}{\\mb_0}{\\Sb_0} $$\n",
    "Now we need to find $p(\\wb \\mid \\tb)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a marginal Gaussian for **x** and a conditional gaussian for **y** given **x** of the form\n",
    "\n",
    "\\begin{array}{rl}\n",
    "p(\\xb) &= \\Nl{\\xb}{\\mub}{\\li}\\\\\n",
    "p(\\yb \\mid \\xb) &= \\Nl{\\yb}{\\Ab\\xb + \\bb}{\\Lbi}\n",
    "\\\\\n",
    "\\color{green}{\\text{Conditional }}\n",
    "p(\\xb \\mid \\yb)\n",
    "&=\n",
    "\\Nl\n",
    "{\\xb}\n",
    "{\\Sigma \\left\\{ \\At\\Lb(\\yb-\\bb) + \\Lambda\\mub \\right\\}}\n",
    "{\\Sigma}\n",
    "\\\\\n",
    "\\text{where }\n",
    "\\Sigma &= \\left(\\Lambda + \\At\\Lb\\Ab\\right)^{-1}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here\n",
    "$$\n",
    "\\arrthree{\n",
    "\\xb \\equiv \\wb & \n",
    "\\mub \\equiv \\mb_0 &\n",
    "\\li \\equiv \\Sb_0 \\\\\n",
    "\\yb \\equiv \\tb &\n",
    "\\Ab \\equiv \\Phib & \n",
    "\\Lb \\equiv \\beta \\I\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the posterior is given by\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\wb \\mid \\tb)\n",
    "&=\n",
    "\\Nl{\\wb}{\\mb_N}{\\Sb_N}\n",
    "\\\\\n",
    "\\text{where }\n",
    "\\mb_N\n",
    "&=\n",
    "\\Sigma \\left\\{ \\At\\Lb(\\yb-\\bb) + \\Lambda\\mub \\right\\}\n",
    "=\n",
    "\\Sb_N \\left\\{ \\Phibt \\beta \\tb + \\Sb_0^{-1} \\mb_0\\right\\}\n",
    "=\n",
    "\\Sb_N \\left( \\beta \\Phibt \\tb + \\Sb_0^{-1} \\mb_0\\right)\n",
    "\\\\\n",
    "\\Sb_N^{-1}\n",
    "&=\n",
    "\\left(\\Lambda + \\At\\Lb\\Ab\\right)\n",
    "=\n",
    "\\left(\\Sb_0^{-1} + \\Phibt \\beta \\Phib \\right)\n",
    "=\n",
    "\\left(\\Sb_0^{-1} + \\beta \\Phibt \\Phib \\right)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since posterior is Gaussian, mode = mean, which implies $\\ml{\\wb} = \\mb_N$\n",
    "* For an infinitely broad prior, $\\Sb_0 = \\inv{\\alpha} \\I$ with $\\alpha \\rightarrow 0$, the mean $\\mb_N \\rightarrow \\ml{\\wb}$\n",
    "* Similarly, for N=0, mean reverts to the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, lets consider the prior as an isotropic Gaussian with precision $\\alpha$, such that\n",
    "<div id='BayesianLinearRegressionPosteriorParameters'/>\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\wb \\mid \\alpha)\n",
    "&=\n",
    "\\Nl{\\wb}{\\mathbf{0}}{\\alpha^{-1}\\I}\n",
    "}\n",
    "$$\n",
    "\n",
    "Thus the posterior parameters becomes\n",
    "\n",
    "$$\n",
    "\\arrthree{\n",
    "\\mb_N\n",
    "&=\n",
    "\\Sb_N (\\beta \\Phib^T \\tb)\n",
    "=\n",
    "\\beta \\Sb_N \\Phib^T \\tb\n",
    "\\\\\n",
    "\\Sb_N^{-1} \n",
    "&=\n",
    "\\alpha\\I + \\beta \\Phib^T \\Phib\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the thing to note here is $\\inv{\\Sb_N}$ depends on $\\Phib$,  \n",
    "which means that the precision/covar depends on $\\xb$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log of the posterior given by the sum of the log likelihood and log prior, as\n",
    "$$\n",
    "\\ln ~p(\\wb \\mid \\tb)\n",
    "=\n",
    "-\\dfrac{\\beta}{2}\n",
    "\\sumnN \\sqrbrc{ t_n - \\wt \\phi(\\xb_n)}\n",
    "-\\dfrac{\\alpha}{2} \\wt \\wb\n",
    "+ \\text{ const}\n",
    "$$\n",
    "The max of this posterior wrt **w** is equivalent to \n",
    "minimization of the sum-of-the-squares error function\n",
    "with the addition of the quadratic regularization term,\n",
    "with $\\lambda = \\alpha / \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_f(x, a):\n",
    "    return a[0] + a[1]*1*x"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forms a meshgrid and computes the value of the gaussian at each gridpoint\n",
    "def show_gaussian(mean, precision_mat):\n",
    "    in_pts = 100\n",
    "    x = np.linspace(-1,1,in_pts)\n",
    "    xv,yv=np.meshgrid(x,x)\n",
    "    #coefficient = sqrt(\\beta)/(2 \\pi)\n",
    "    coeff =math.sqrt(np.linalg.det(precision_mat)/(2.*math.pi))\n",
    "    img = np.zeros((in_pts,in_pts))\n",
    "    for ix in range(in_pts):\n",
    "        for iy in range(in_pts):\n",
    "            x = np.array([xv[ix,iy],yv[ix,iy]]).reshape(-1,1)\n",
    "            # -1/2 * (x-mu)T Precision (x-mu)\n",
    "            expt = -1./2. * (x - mean).T @ precision_mat @ (x-mean)\n",
    "            img[ix,iy] = coeff * math.exp(expt[0,0])\n",
    "    ticks = np.arange(-1,1,1.0)\n",
    "    extent = (-1,1,-1,1)\n",
    "    plt.imshow(img, extent=extent, origin='lower')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forms a meshgrid and computes the value of the gaussian at each gridpoint\n",
    "# using broadcasting\n",
    "def show_gaussian2(mean, precision_mat):\n",
    "    in_pts = 100\n",
    "    x = np.linspace(-1,1,in_pts)\n",
    "    xv,yv=np.meshgrid(x,x)\n",
    "    #coefficient = sqrt(\\beta)/(2 \\pi)\n",
    "    coeff =math.sqrt(np.linalg.det(precision_mat)/(2.*math.pi))\n",
    "    xv = xv.ravel().reshape(-1,1) # make em column vectors\n",
    "    yv = yv.ravel().reshape(-1,1)\n",
    "    # X = [xv yv] -> [N x 2]\n",
    "    X = np.hstack([xv,yv])\n",
    "    mean_vector = mean.reshape(1,-1) # make it col vector\n",
    "    X_m_u = (X - mean_vector) # [broadcast] find the diff of each pt with mean\n",
    "    # [broadcast] coeff * math.e**(-1/2 * (x-mu)T Precision (x-mu))\n",
    "    img2 = coeff * math.e**(-1./2. * np.sum(X_m_u @ precision_mat * X_m_u, 1))\n",
    "    # reshape it back to an image\n",
    "    img2 = img2.reshape(in_pts,in_pts)\n",
    "    ticks = np.arange(-1,1,1.0)\n",
    "    extent = (-1,1,-1,1)\n",
    "    plt.imshow(img2, extent=extent, origin='lower')\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the posterior as given in text\n",
    "def compute_posterior(in_samples,a0,a1,beta_sd,alpha):\n",
    "    beta = 1./beta_sd**2\n",
    "    mean_0 = np.array([0,0]).reshape(-1,1)\n",
    "    xn = (np.random.rand(in_samples)*2.0 - 1.0).reshape(-1,1)\n",
    "    fn = fun_f(xn, [a0,a1]).reshape(-1,1)\n",
    "    data = np.hstack([xn, fn])\n",
    "    xn_noise = np.random.normal(0,beta_sd,in_samples).reshape(-1,1)\n",
    "    # tn = a0 + a1*x + N(0,1/beta)\n",
    "    tn = np.array(fn + xn_noise).reshape(-1,1)\n",
    "    # phi = [ones^T x^T]\n",
    "    phi = np.hstack([np.ones_like(xn),xn])\n",
    "    # Sn = beta*phi^T*phi + alpha*I\n",
    "    sn_inv = beta * phi.T @ phi + alpha*np.eye(2)\n",
    "    sn = np.linalg.inv(sn_inv)\n",
    "    # m_n = beta*Sn*Phi^T*Tn\n",
    "    mean_n = beta * sn @ phi.T @ tn\n",
    "    return (data, mean_n, sn, sn_inv)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bay_lin_reg(in_samples,a0,a1,beta_sd,alpha):\n",
    "    data, mean_n, sn, sn_inv = compute_posterior(in_samples,a0,a1,beta_sd,alpha)\n",
    "    plt.plot(a0,a1,'ok', markersize=6, label='gt')\n",
    "    plt.plot(a0,a1,'or', markersize=3, label='gt')\n",
    "    plt.plot(a0,a1,'+w', markersize=30, label='gt')\n",
    "    show_gaussian2(mean_n, sn_inv)\n",
    "    plt.legend(loc=(1,0.5))\n",
    "    plt.show()\n",
    "    #plt.plot(data[:,0], data[:,1], 'o')\n",
    "    #plt.xlim([-1,1]); plt.ylim([-1,1])\n",
    "    #plt.show()\n",
    "    return (mean_n, sn_inv)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "# mean_n, sn, sn_inv = compute_posterior(40,-0.3,0.5,0.2,2.0)\n",
    "#timeit.timeit('show_gaussian(mean_n, sn_inv)','from __main__ import mean_n, sn_inv, show_gaussian')\n",
    "#timeit.timeit('show_gaussian2(mean_n, sn_inv)','from __main__ import mean_n, sn_inv, show_gaussian2')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_bay_lin_reg(in_samples=1,\n",
    "                         a0=-0.3,a1=0.5,\n",
    "                         beta_sd=0.25,alpha=2.0,\n",
    "                         show_all=True):\n",
    "    show_bay_lin_reg(in_samples,a0,a1,beta_sd,alpha)\n",
    "    \n",
    "interact(interact_bay_lin_reg,\n",
    "         in_samples=(0,40),\n",
    "         a0=(-1,1,0.1),a1=(-1,1,0.1),\n",
    "         beta_sd=(0,1,0.05),alpha=(1,5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usually not interested in the value of **w** itself.\n",
    "* need to make prediction of *t* for new values of **x**\n",
    "* Predictive Distribution $\n",
    "p(t \\mid \\tb, \\alpha, \\beta)\n",
    "=\n",
    "\\int p(t \\mid \\wb, \\beta) p(\\wb \\mid \\tb, \\alpha, \\beta) ~d\\wb\n",
    "$\n",
    "* The conditional distribution is given by\n",
    "$$\n",
    "p(t \\mid \\wb, \\beta) = \\Nl{t}{y(\\xb,\\wb)}{\\beta^{-1}}\n",
    "$$\n",
    "* Posterior is given by\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\wb \\mid \\tb)\n",
    "&=\n",
    "\\Nl{\\wb}{\\mb_N}{\\Sb_N}\n",
    "\\\\\n",
    "\\text{where }\n",
    "\\\\\n",
    "\\mb_N &= \\Sb_N \\left( \\Sb_0^{-1} \\mb_0 + \\beta \\Phib^T \\Phib \\right)\n",
    "\\\\\n",
    "\\Sb_{N}^{-1} &= \\Sb_{0}^{-1} + \\beta \\Phib^T \\Phib\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <a href='../Gaussian Stuff.ipynb#BayesTheoremForGaussianVariables'>Bayes' Theorem for Gaussian Variables</a>, we have the following\n",
    "\n",
    "Given a marginal Gaussian for **x** and a conditional gaussian for **y** given **x** of the form\n",
    "\n",
    "$$\n",
    "\\arrthree{\n",
    "p(\\xb) \n",
    "&=\n",
    "\\Nl{\\xb}{\\mub}{\\li}\n",
    "\\\\\n",
    "p(\\yb \\mid \\xb)\n",
    "&=\n",
    "\\Nl{\\yb}{\\Ab\\xb + \\bb}{\\Lbi}\n",
    "\\\\\n",
    "\\color{green}{\\text{Marginal }}\n",
    "p(\\yb)\n",
    "&=\n",
    "\\Nl{\\yb}{\\Ab\\mub+\\bb}{\\Lbi + \\Ab\\Lambda^{-1}\\At}\n",
    "\\\\\n",
    "}\n",
    "$$\n",
    "\n",
    "Here\n",
    "$$\n",
    "\\arrthree{\n",
    "\\xb &\\equiv \\wb\n",
    "&\n",
    "\\mub &\\equiv \\mb_N\n",
    "&\n",
    "\\li &\\equiv \\Sb_N\n",
    "\\\\\n",
    "\\yb &\\equiv t\n",
    "&\n",
    "\\At,\\bb &\\equiv \\Phib,\\mathbf{0}\n",
    "&\n",
    "\\Lbi &\\equiv \\beta^{-1}\n",
    "}\n",
    "$$\n",
    "\n",
    "Hence\n",
    "$$\n",
    "\\arrthree{\n",
    "\\E{\\yb}\n",
    "&=\n",
    "\\Ab \\mub + \\bb = \n",
    "\\mb_N^T \\Phib\n",
    "\\\\\n",
    "\\sigma(\\yb)\n",
    "&=\n",
    "\\beta^{-1} + \\Phib^T \\Sb_N \\Phib\n",
    "}\n",
    "$$\n",
    "\n",
    "The second term goes to zero as N increases ([Qazaz][qazaz1997]).\n",
    "\n",
    "[qazaz1997]: http://dl.acm.org/citation.cfm?id=268081 \"Cambridge University Press. Qazaz, C. S., C. K. I. Williams, and C. M. Bishop (1997). An upper bound on the Bayesian error bars for generalized linear regression. In S. W. Ellacott, J. C. Mason, and I. J. Anderson (Eds.), Mathematics of Neural Networks: Models, Algorithms and Applications, pp. 295–299. Kluwer.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we treat both $\\wb, \\beta$ as unknown, the predictive distribution becomes a Student't t-distribution (<a href='/notebooks/void-main/Gaussian%20Stuff.ipynb#Unknown-mean,-unknown-variance'>Unknown Mean,Variance</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis functions\n",
    "def gimme_phis(x, degree):\n",
    "    x_out = np.ones((x.shape[0], degree+1))\n",
    "    for degree in range(1, degree+1):\n",
    "        x_out[:,degree:degree+1] = x**degree\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(in_samples):\n",
    "    # sample random theta from [0,2*pi]\n",
    "    in_pts_pred = 10**2\n",
    "    thetas = (np.random.rand(in_samples)*2*math.pi).reshape(-1,1)\n",
    "    thetas_plt = np.linspace(0, 2*math.pi, in_pts_pred).reshape(-1,1)\n",
    "    return (thetas, thetas_plt)\n",
    "def plot_sine(thetas):\n",
    "    plt.plot(thetas, [math.sin(theta) for theta in thetas],label='sine', linewidth=4, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.random.normal"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen from sine and add gaussian noise\n",
    "def generate_tn(in_samples, thetas, beta_sd = 0.2):\n",
    "    beta = 1./(beta_sd**2)\n",
    "    xn_noise = np.random.normal(0, beta_sd, in_samples).reshape(-1,1)\n",
    "    tn = [math.sin(theta[0]) for theta in thetas]\n",
    "    tn = np.array(tn).reshape(-1,1)\n",
    "    tn = tn + xn_noise\n",
    "    return tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Sb_N^{-1} \n",
    "&=\n",
    "\\alpha\\I + \\beta \\Phib^T \\Phib\n",
    "\\\\\n",
    "\\mb_N\n",
    "&=\n",
    "\\Sb_N (\\beta \\Phib^T \\tb)\n",
    "=\n",
    "\\beta \\Sb_N \\Phib^T \\tb\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_parameters(thetas, degree, tn, beta, alpha):\n",
    "    phi_posterior = gimme_phis(thetas, degree)\n",
    "    # Sn = beta*phi^T*phi + alpha*I\n",
    "    sn_inv = beta * phi_posterior.T @ phi_posterior + alpha*np.eye(degree+1)\n",
    "    sn = np.linalg.inv(sn_inv)\n",
    "    # m_n = beta*Sn*Phi^T*Tn\n",
    "    mean_n = beta * sn @ phi_posterior.T @ tn\n",
    "    return (mean_n, sn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\E{\\yb}\n",
    "&=\n",
    "\\mb_N^T ~\\Phi(\\xb)\n",
    "\\\\ &=\n",
    "\\Phib \\mb_N\n",
    "\\\\\n",
    "\\sigma^2\n",
    "&=\n",
    "\\beta^{-1} + \\Phi^T(\\xb) ~\\Sb_N ~\\Phi(\\xb)\n",
    "\\\\ &=\n",
    "\\beta^{-1} + \\Phib \\Sb_N \\Phib^T\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(thetas, degree, beta, mean_n, sn):\n",
    "    phi_pred = gimme_phis(thetas, degree)\n",
    "    mean_pred = phi_pred @ mean_n\n",
    "    print(phi_pred.shape, sn.shape)\n",
    "    covar_pred = 1./beta + np.sum(phi_pred @ sn @ phi_pred.T, 1).reshape(-1,1)\n",
    "    print(covar_pred.shape)\n",
    "    return (mean_pred, covar_pred)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covar_pred(thetas, mean, covar):\n",
    "    for xy in np.hstack([thetas, mean, covar]):\n",
    "        x, y1, y2 = xy[0], xy[1]-xy[2], xy[1]+xy[2]\n",
    "        plt.plot((x,x),(y1,y2),'-', color=(.969, .812, .812), linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree, in_samples, beta_sd, alpha = 3, 10, 0.2, 2.0\n",
    "\n",
    "def interact_bayesian_prediction(degree=4, in_samples=80, beta_sd=0.2, alpha=2.0):\n",
    "    beta = 1./(beta_sd**2)\n",
    "    thetas, thetas_plt = get_data(in_samples)\n",
    "    tn = generate_tn(in_samples, thetas, beta_sd)\n",
    "\n",
    "    mean_n, sn = compute_parameters(thetas, degree, tn, beta, alpha)\n",
    "    mean_pred, covar_pred = predict(thetas_plt, degree, beta, mean_n, sn)\n",
    "    sd_pred = np.sqrt(covar_pred)\n",
    "    #print(sd_pred.T)\n",
    "\n",
    "    plot_covar_pred(thetas_plt, mean_pred, sd_pred)\n",
    "    plt.plot(thetas_plt, mean_pred, color='r', linewidth=4, label='predicted mean')\n",
    "    plot_sine(thetas_plt)\n",
    "    plt.plot(thetas, tn, 'ob',label='tn')\n",
    "    plt.legend(loc=(1,0.5))\n",
    "    plt.show()\n",
    "interact(interact_bayesian_prediction, degree=(0,10), in_samples=(1,100,10),\n",
    "         beta_sd=(0.1, 2.0, 0.1), alpha=(1.0, 5.0, 0.5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beauty is that the uncertainty is low in the areas where we have seen data and more when we haven't.  \n",
    "Why does that happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2 = \\beta^{-1} + \\Phi^T(\\xb) ~\\Sb_N ~\\Phi(\\xb)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consequence it can be shown (Qazaz et al., 1997) that $\\sigma^2_N(\\xb) \\ll \\sigma^2_{N+1}(\\xb)$. \n",
    "In the limit $N \\rightarrow \\infty$, the second term in above equation goes to zero, and the variance of the predictive distribution arises solely from the additive noise governed by the parameter $\\beta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not w/o a problem though  \n",
    "In regions away from basis function centers, contribution from 2dn term of sigma becomes zero.  \n",
    "Hence, model becomes very confident in its predictions when extrapolating outside the region occupied by basis functions  \n",
    "\n",
    "This can be avoided by using GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivalent Kernel\n",
    "\n",
    "* The posterior mean (<a href='#BayesianLinearRegressionPosteriorParameters'>Posterior Mean</a>) is given by $\\mb_N = \\beta \\Sb_N \\Phib^T \\tb$.\n",
    "* Sub this into the regression function, we have\n",
    "$$\n",
    "\\arrthree{\n",
    "y(\\xb, \\mb_N)\n",
    "&=\n",
    "\\mb_N^T \\phi(x)\n",
    "\\\\\n",
    "&=\n",
    "\\phi(x) \\mb_N^T\n",
    "\\\\\n",
    "&=\n",
    "\\beta \\phi(\\xb)^T \\Sb_N \\Phib^T \\tb\n",
    "\\\\\n",
    "&=\n",
    "\\beta \\phi(\\xb)^T \\Sb_N\n",
    "\\mat{\n",
    "\\vdots      & \\cdots & \\vdots \\\\\n",
    "\\phi(\\xb_1) & \\cdots & \\phi(\\xb_N) \\\\\n",
    "\\vdots      & \\cdots & \\vdots \\\\\n",
    "}\n",
    "\\tb\n",
    "\\\\\n",
    "&=\n",
    "\\sumnN \\beta \\phi(\\xb)^T \\Sb_N \\phi(\\xb_n) t_n\n",
    "\\\\\n",
    "&=\n",
    "\\sumnN k(\\xb,\\xb_n) t_n\n",
    "\\\\\n",
    "\\text{where }\\\\\n",
    "k(\\xb,\\xb^{\\prime})\n",
    "&=\n",
    "\\beta \\phi(\\xb)^T \\Sb_N \\phi(\\xb_n)\n",
    "}\n",
    "$$\n",
    "\n",
    "* *k* is called *smoother matrix* or the *equivalent kernel*\n",
    "* *Linear Smoothers*: Makes predictions by taking linear combination of the training set target values\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\sigma[y(\\xb),y(\\xb^{\\prime})]\n",
    "&=\n",
    "\\sigma[\\phi(\\xb)^T\\wb, \\wb^T \\phi(\\xb^{\\prime})]\n",
    "\\\\\n",
    "&=\n",
    "\\phi(\\xb)^T \\Sb_N \\phi(\\xb^{\\prime})\n",
    "\\\\\n",
    "&=\n",
    "\\beta^{-1} k(\\xb, \\xb^{\\prime})\n",
    "}\n",
    "$$\n",
    "[? How the fuck did you get to that second step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "214px",
   "left": "1713.38px",
   "right": "20px",
   "top": "122px",
   "width": "177px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

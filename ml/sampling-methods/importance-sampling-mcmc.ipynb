{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random as rnd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# required for interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy.polynomial as np_poly\n",
    "\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization  \n",
    "$ \\newcommand{\\E}[1]{\\mathbb{E}\\left[#1\\right]}$  \n",
    "$ \\newcommand{\\V}[1]{\\mathbb{V}\\left[#1\\right]}$\n",
    "$ \\newcommand{\\cov}[1]{\\text{cov} \\sigma\\left[#1\\right]}$\n",
    "$ \\newcommand{\\EXP}[1]{\\exp\\left(#1\\right)}$  \n",
    "$ \\newcommand{\\P}{\\mathbb{P}}$\n",
    "$\\newcommand{\\mat}[1]{\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "#1\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "}$\n",
    "$\\newcommand{\\commentgray}[1]{\\color{gray}{\\text{#1}}}$\n",
    "$\\newcommand{\\arrthree}[1]{\n",
    "\\begin{array}{rlr}\n",
    "#1\n",
    "\\end{array}\n",
    "}\n",
    "\\newcommand{\\mats}[1]{\n",
    "\\begin{\\smallmatrix} #1 \\end{\\smallmatrix}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\newcommand{\\sumiN}{\\sum_{i=1}^{N}}\n",
    "\\newcommand{\\sumjN}{\\sum_{j=1}^{N}}\n",
    "\\newcommand{\\sumnN}{\\sum_{n=1}^{N}}\n",
    "\\newcommand{\\sumkM}{\\sum_{k=1}^{M}}\n",
    "\\newcommand{\\sumkMl}{\\sum_{k=1}^{M-1}}\n",
    "\\newcommand{\\sumjMl}{\\sum_{j=1}^{M-1}}\n",
    "\\newcommand{\\prodnN}{\\prod_{n=1}^{N}}\n",
    "\\newcommand{\\prodiN}{\\prod_{i=1}^{N}}\n",
    "\\newcommand{\\fracone}[1]{\\frac{1}{#1}}\n",
    "\\newcommand{\\arr}[1]{\\begin{array}{rlr}#1\\end{array}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\newcommand{\\const}{\\text{const.}}\n",
    "$\n",
    "\n",
    "\n",
    "$\n",
    "\\newcommand{\\chib}{\\boldsymbol{\\chi}}\n",
    "$\n",
    "\n",
    "$\\newcommand{\\Nl}[3]{\\mathcal{N}\\left(#1 \\mid #2, #3\\right)}$\n",
    "$\\newcommand{\\Nstdx}{\\Nl{\\mathbf{x}}{\\mathbf{\\mu}}{\\Sigma}}$\n",
    "$\\newcommand{\\ab}{\\mathbf{a}}$\n",
    "$\\newcommand{\\Ab}{\\mathbf{A}}$\n",
    "$\\newcommand{\\Abt}{\\Ab^T}$\n",
    "$\\newcommand{\\bb}{\\mathbf{b}}$\n",
    "$\\newcommand{\\Bb}{\\mathbf{B}}$\n",
    "$\\newcommand{\\Cb}{\\mathbf{C}}$\n",
    "$\\newcommand{\\Db}{\\mathbf{D}}$\n",
    "$\\newcommand{\\Lb}{\\mathbf{L}}$\n",
    "$\\newcommand{\\Lbi}{\\Lb^{-1}}$\n",
    "$\\newcommand{\\mb}{\\mathbf{m}}$\n",
    "$\\newcommand{\\Mb}{\\mathbf{M}}$\n",
    "$\\newcommand{\\Rb}{\\mathbf{R}}$\n",
    "$\\newcommand{\\ub}{\\mathbf{u}}$\n",
    "$\\newcommand{\\Xb}{\\mathbf{X}}$\n",
    "$\\newcommand{\\xb}{\\mathbf{x}}$\n",
    "$\\newcommand{\\xab}{\\mathbf{x_a}}$\n",
    "$\\newcommand{\\xabt}{\\mathbf{x_a}^T}$\n",
    "$\\newcommand{\\xbb}{\\mathbf{x_b}}$\n",
    "$\\newcommand{\\xbbt}{\\mathbf{x_b}^T}$\n",
    "$\\newcommand{\\yb}{\\mathbf{y}}$\n",
    "$\\newcommand{\\zb}{\\mathbf{z}}$\n",
    "$\\newcommand{\\Ub}{\\mathbf{U}}$\n",
    "\n",
    "$\\newcommand{\\thetab}{\\pmb{\\theta}}$\n",
    "$\\newcommand{\\thetai}{\\theta^{(i)}}$\n",
    "$\\newcommand{\\mub}{\\pmb{\\mu}}$\n",
    "$\\newcommand{\\muab}{\\pmb{\\mu}_a}$\n",
    "$\\newcommand{\\mubb}{\\pmb{\\mu}_b}$\n",
    "\n",
    "$\n",
    "\\newcommand{\\xt}[1]{x^{(#1)}}\n",
    "\\newcommand{\\thetat}[1]{\\theta^{(#1)}}\n",
    "$\n",
    "\n",
    "$\\newcommand{\\saa}{\\Sigma_{aa}}$\n",
    "$\\newcommand{\\sab}{\\Sigma_{ab}}$\n",
    "$\\newcommand{\\sba}{\\Sigma_{ba}}$\n",
    "$\\newcommand{\\sbb}{\\Sigma_{bb}}$\n",
    "$\\newcommand{\\laa}{\\Lambda_{aa}}$\n",
    "$\\newcommand{\\laai}{\\Lambda_{aa}^{-1}}$\n",
    "$\\newcommand{\\lab}{\\Lambda_{ab}}$\n",
    "$\\newcommand{\\lba}{\\Lambda_{ba}}$\n",
    "$\\newcommand{\\lbb}{\\Lambda_{bb}}$\n",
    "$\\newcommand{\\lbbi}{\\Lambda_{bb}^{-1}}$\n",
    "$\\newcommand{\\li}{\\Lambda^{-1}}$\n",
    "$\n",
    "\\newcommand{\\etab}{\\pmb{\\eta}}\n",
    "\\newcommand{\\etat}{\\eta^T}\n",
    "\\newcommand{\\etabt}{\\etab^T}\n",
    "$\n",
    "\n",
    "$\\newcommand{\\multivarcoeff}{\\frac{1}{(2\\pi)^{D/2}}\n",
    "\\frac{1}{\\left| \\mathbf{\\Sigma}\\right|^{1/2}}}$\n",
    "$\\newcommand{\\multivarexp}[2]\n",
    "{\n",
    "\\left\\{\n",
    " -\\frac{1}{2} \n",
    " {#1}^T \n",
    " #2\n",
    " {#1}\n",
    "\\right\\}\n",
    "}$\n",
    "$\\newcommand{\\multivarexpx}[1]{\\multivarexp{#1}{\\Sigma^{-1}}}$\n",
    "$\\newcommand{\\multivarexpstd}{\\multivarexpx{(\\xb-\\mub)}}$\n",
    "$\\newcommand{\\gam}{\\operatorname{Gam}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo\n",
    "1. http://videolectures.net/mlss08au_freitas_asm/\n",
    "1. why will stochastic matrix converge to a steady state?\n",
    "   1. is it coz only one of the eigen values will be one and that eigen vector will be the steady state vector?\n",
    "1. http://www.sosmath.com/matrix/markov/markov.html\n",
    "1. https://en.wikipedia.org/wiki/PageRank\n",
    "1. https://en.wikipedia.org/wiki/Stochastic_volatility\n",
    "1. markov chains - strang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance sampling\n",
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Logistic regression\n",
    "-----------------------------\n",
    "\n",
    "$y_i \\in {0,1}$\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "p(\\yb \\mid \\Xb, \\thetab)\n",
    "&=\n",
    "\\prodiN \\text{Ber} (y_i \\mid \\sigma(\\xb_i\\thetab))\n",
    "\\\\ &=\n",
    "\\prodiN\n",
    "\\left[ \\fracone{1+e^{-\\xb_i \\thetab}} \\right]^{y_i}\n",
    "\\left[ 1-\\fracone{1+e^{-\\xb_i \\thetab}} \\right]^{1 - y_i}\n",
    "\\end{array}\n",
    "\n",
    "Prior\n",
    "$$\n",
    "p(\\thetab) = \\fracone{\\sqrt{2\\pi\\sigma^2}}\n",
    "\\exp \\left( -\\fracone{2\\sigma^2} \\thetab^T \\thetab \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior\n",
    "$$\n",
    "p(\\thetab \\mid \\Xb, \\yb)\n",
    "= \n",
    "\\fracone{Z} p(\\yb \\mid \\Xb, \\thetab) p(\\thetab)\n",
    "$$\n",
    "\n",
    "If we take the negative log likelihood, we get\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "J(\\theta) &= \n",
    "- \\log p(\\thetab \\mid \\Xb, \\yb)\n",
    "\\\\\n",
    "&= \\const - \\log p(\\yb \\mid \\Xb, \\thetab)\n",
    "-\\log p(\\thetab)\n",
    "\\\\\n",
    "&= \\const - \\sumiN y_i \\log(\\pi_i) + (1-y_i) \\log(1-\\pi_i)\n",
    "\\\\ & -\\fracone{2\\sigma^2} \\lVert \\thetab \\rVert_{2}^{2}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis is more like ridge regression where the last terms plays the role of the (L2) regularizer, with $\\fracone{2\\sigma^2}$ acting as the coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{rlr}\n",
    "Z &= \\int p(y \\mid \\theta) p(\\theta) ~d\\theta\n",
    "\\\\\n",
    "&=\\int \\frac{p(y \\mid \\theta) p(\\theta)}{q(\\theta)} q(\\theta) ~d\\theta\n",
    "\\end{array}\n",
    "\n",
    "Typically you want a q with heavy tails\n",
    "\n",
    "$q(\\theta) = \\mathcal{N}(0, 1000)$\n",
    "with large variance\n",
    "\n",
    "User has to be decide $q(\\theta)$\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "Z &= \\int \\frac{p(y \\mid \\theta) p(\\theta)}{q(\\theta)} q(\\theta) ~d\\theta\n",
    "\\\\\n",
    "&= \\int w(\\theta) ~q(\\theta) ~d\\theta\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can evaluate $w(\\theta)$\n",
    "1. $q(\\theta)$: this a gaussian and can be evaluated\n",
    "1. $p(y \\mid \\theta)$: bernoulli, you can plugin $\\theta$ and eval\n",
    "1. $p(\\theta)$: gaussian, plugin $\\theta$ and eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample from normal, N points\n",
    "$$\n",
    "\\theta^{i} \\approx q(\\theta), i = 1 \\dots N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z is nothing but the expected value of $w(\\theta)$  \n",
    "that is,\n",
    "$$\n",
    "Z \\approx \\fracone{N} \\sumiN w(\\theta^{(i)})\n",
    "$$\n",
    "\n",
    "as $N \\rightarrow \\infty$, the approximation becomes the real value, according to the strong law of large numbers, avg tends to expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reason why we do ML:  \n",
    "if the #samples tend to $\\infty$, the val will concentrate on $\\hat{\\theta}_{ML}$, converges to the actual solution\n",
    "\n",
    "If sample set is small, there will be variance.\n",
    "\n",
    "finding map solution \n",
    "1. multiply likelihood and prior\n",
    "1. normalize the product\n",
    "1. divide the product by the normalizer\n",
    "1. find the val with max. mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do i write down the histogram of $p(\\thetab \\mid \\mathcal{D})$?\n",
    "\n",
    "one way to do it is the following...  \n",
    "The claim is ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{rlr}\n",
    " p(\\theta | \\text{data})\n",
    "&=\n",
    "\\fracone{N} \\sumiN w(\\theta^{(i)}) \\delta_{\\theta^{(i)}}(d\\theta) \n",
    "\\end{array}\n",
    "\n",
    "$\\delta_{\\theta^{(i)}}(d\\theta)$: no. of samples of $\\theta^{(i)}$ that fell in the interval $d\\theta$ \n",
    "\n",
    "But, using [Lesbegue integral](https://en.wikipedia.org/wiki/Lebesgue_integration), we have\n",
    "$$\n",
    "\\int p(d\\theta) \\equiv \\int p(\\theta) ~d\\theta\n",
    "$$\n",
    "\n",
    "that is, probability of \"an interval\" is height times the width.\n",
    "\n",
    "that is, the height of the bar is the value of the density,\n",
    "area is the probability, the width: length of interval aka measure\n",
    "\n",
    "The riemann integral approaches integrals by finding the areas of successive vertical bars, while lebesgue using horizontal bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\theta \\mid \\text{data})$: (probability) density function\n",
    "\n",
    "pick a value $\\theta^{(i)}$ and consider a \"bar\" or interval of width $d\\theta$ around it. the area of it is called the probability. the prob that $\\theta$ will fall in that interval.\n",
    "\n",
    "for example, in case of the normal distribution, the right side half has an area 0.5, which is to say, the probability of a sample falling on to the right side is 0.5. coz we consider/measure probability on intervals/areas\n",
    "\n",
    "from [wikipedia](https://www.wikiwand.com/en/Probability_density_function#/Further_details)\n",
    "\n",
    "the uniform distribution in the interval [0,0.5] has a density 2,\n",
    "since $\\int_{0}^{1/2} 2 dx = 1$. so, here density is more than 1. \n",
    "density in $\\text{general}^?$ needs to be positive. \n",
    "but the prob of the val from UD falling in a subinterval inside [0, 0.5] will be less than or equal 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D dim: $n^D$ samples, curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to fucking beat the curse of dimensionality??\n",
    "\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "p(y_{t+1} \\mid x_{t+1}, \\yb, \\Xb)\n",
    "&=\n",
    "\\int p(y_{t+1} \\mid x_{t+1}, \\theta) ~p(d\\theta \\mid \\yb, \\Xb)\n",
    "\\\\\n",
    "&=\n",
    "\\int p(y_{t+1} \\mid x_{t+1}, \\theta) ~p(\\theta \\mid \\yb, \\Xb) ~d\\theta\n",
    "\\end{array}\n",
    "\n",
    "this essentially removes theta.\n",
    "\n",
    "note that here the predictive distribution is obtained by integrating the posterior over all the values of $\\theta$. \n",
    "Bayesians loathe the idea of a single theta. they need a weighted (by probability) prediction aka expected value under a probability distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus,  \n",
    "\\begin{array}{rlr}\n",
    "p(y_{t+1} \\mid x_{t+1}, \\yb, \\Xb)\n",
    "& \\approx\n",
    "\\int p(y_{t+1} \\mid x_{t+1}, \\theta)\n",
    "\\fracone{N} \\sumiN ~w(\\theta^{(i)}) ~\\delta_{\\theta^{(i)}}(d\\theta)\n",
    "\\\\ &=\n",
    "\\fracone{N} \\sumiN \\int p(y_{t+1} \\mid x_{t+1}, \\theta) ~w(\\theta^{(i)}) ~\\delta_{\\theta^{(i)}}(d\\theta)\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the $\\delta$ function is a dirac measure function, which is a spike at a given value. so the integration with such a function as a constituent will be equivalent to the evaluation at that value.\n",
    "\n",
    "that is,\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "p(y_{t+1} \\mid x_{t+1}, \\yb, \\Xb)\n",
    "& \\approx\n",
    "\\fracone{N} \\sumiN\n",
    "\\underbrace{p(y_{t+1} \\mid x_{t+1}, \\theta^{(i)})}_{likelihood}\n",
    "~w(\\theta^{(i)})\n",
    "\\end{array}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un-normalized importance sampling\n",
    "-----------------------------------\n",
    "\n",
    "most of the time in bay. inf, we donno the norm. constant.  \n",
    "in log reg, we have to do sth different.\n",
    "\n",
    "\\begin{array}{rlr}\n",
    "p(\\theta \\mid \\mathcal{D})\n",
    "&=\n",
    "\\fracone{Z} p(\\mathcal{D} \\mid \\theta) p(\\theta)\n",
    "\\\\ &=\n",
    "\\frac\n",
    "{p(\\mathcal{D} \\mid \\theta) p(\\theta)}\n",
    "{\\int p(\\mathcal{D} \\mid \\theta) p(\\theta) ~d\\theta}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictive distribution: expectation of the likelihood.  \n",
    "what if i want to compute the expectation of a general function?  \n",
    "\n",
    "\\begin{array}{rlr}\n",
    "p(y_{t+1} \\mid \\mathcal{D})\n",
    "\\\\\n",
    "p(y_{t+1} \\mid \\Xb, \\yb) &= \n",
    "\\fracone{Z}\n",
    "\\int\n",
    "p(y_{t+1} \\mid x_{t+1}, \\theta)\n",
    "~p(\\mathcal{D} \\mid \\theta)\n",
    "~p(\\theta) ~d\\theta\n",
    "\\\\ &=\n",
    "\\frac\n",
    "{\\int\n",
    "p(y_{t+1} \\mid x_{t+1}, \\theta)\n",
    "~p(\\mathcal{D} \\mid \\theta)\n",
    "~p(\\theta) \\frac{q(\\theta)}{q(\\theta)}~d\\theta\n",
    "}\n",
    "{\n",
    "\\int\n",
    "~p(\\mathcal{D} \\mid \\theta)\n",
    "~p(\\theta) \\frac{q(\\theta)}{q(\\theta)} ~d\\theta\n",
    "}\n",
    "\\\\ &=\n",
    "\\frac\n",
    "{\\int\n",
    "p(y_{t+1} \\mid x_{t+1}, \\theta)\n",
    "~w(\\theta) ~q(\\theta) ~d\\theta\n",
    "}\n",
    "{\n",
    "\\int\n",
    "w(\\theta) ~q(\\theta) ~d\\theta\n",
    "}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are apprx the ratio of two integrals at the same time. \n",
    "we apply monte carlo to each one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arr{\n",
    "p(y_{t+1}) &=\n",
    "\\frac{\n",
    "\\fracone{N} \\sumiN w(\\thetai) p(y_{t+1} \\mid x_{t+1}, \\thetai)\n",
    "}{\n",
    "\\fracone{N} \\sumiN w(\\thetai)\n",
    "}\n",
    "\\\\ &=\n",
    "\\sumiN\n",
    "\\tilde{w}_i\n",
    "~p(y_{t+1} \\mid x_{t+1}, \\thetai)\n",
    "}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\tilde{w}_i = \\frac{w(\\thetai)}{\\sumjN w(\\thetai)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "char of $q(\\theta)$  \n",
    "1. its support should cover p\n",
    "1. that is, q should be decently positive when p is positive\n",
    "1. as $n \\rightarrow \\infty$, approaches\n",
    "  1. true value\n",
    "  1. unbiased (applies to normalized case as well)\n",
    "  \n",
    "they do have high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of ways to find q is this.  \n",
    "define $q = \\mathcal{N}(\\mub, \\sigma^2 \\mathcal{I})$  \n",
    "\n",
    "one of the strategies to find q is this.  \n",
    "you can find the mode of the posterior, fit the gaussian there. this is laplacian approximation\n",
    "\n",
    "how to do know if we found the right value of $\\lambda$, the regularization coefficient?   \n",
    "using cross validation  \n",
    "\n",
    "since we are trying to minimize variance, we can\n",
    "1. do bay opt (use the data)\n",
    "1. mu, sigma\n",
    "\n",
    "make sure q is heavy-tailed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when importance sampling in done in a sequential setting, often in the case of radar, finance applications, then it is called particle filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important drawback of importance sampling is that, in high dimension, it is hard to get the support for all the regions where the posterior is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we donno the posterior, esp the regions where it is high,\n",
    "we can use uniform distribution.\n",
    "but, in high dimensions, the probability mass of a uniform distribution will be so low that it will mostly fail to capture the topography of posterior and hence the method fails\n",
    "\n",
    "in most cases, the normalization constant (likelihood times prior) cannot be integrated analytically. if it were, life would be super cool. this is where techniques like importance sampling comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mcmc navigates smartly in the high dimensions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use importance sampling for 3-6 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC\n",
    "=====\n",
    "Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of reweighting, we navigate the space using markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition matrix $\\mathcal{T}$:\n",
    "\\begin{array}{ccc}\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0.1 & 0.9 \\\\\n",
    "0.6 & 0.4 & 0\n",
    "\\end{array}\n",
    "\n",
    "$\\mathcal{T}(i,j)$: prob of shifting from state i to state j.  \n",
    "hence the rows sum to 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a first order MC where the next state depends only the previous state, never beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steady state vector $\\pi_s$ of a transition matrix is defined as,\n",
    "$$\n",
    "T^{\\infty} v_0 = \\pi_s\n",
    "$$\n",
    "or\n",
    "$$\n",
    "T \\pi_s = \\pi_s\n",
    "$$\n",
    "the beauty is the initial vector can be anything.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Irreducability: a single connected component, not a forest of connected components.\n",
    "1. Aperiodicity: no cycles.\n",
    "  1. can be avoided by adding a small value $\\epsilon$ to all the entries of $\\mathcal{T}$. will only the diagonal suffice?\n",
    "    1. done in google page rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the continuous case, the vector has infinite #bins and the vector becomes a function. like gaussian process. and the transition probabilities are given by $p(y \\mid x)$. quite sexy.  \n",
    "$$\n",
    "\\int \\pi(x)\n",
    "~\\underbrace{p(y \\mid x)}_{\n",
    "\\matrix{\n",
    "  \\text{markov chain}\\\\\n",
    "  \\text{kernel}\n",
    "  }\n",
    "}\n",
    "~dx = \\pi(y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in mcmc, we use $\\pi_s$ and construct $\\mathcal{T}$ that will give samples from $\\pi_s$.  \n",
    "in pagerank algo, this is equivalent to knowing the page rank of each webpage, how will you sample from the graph? how will you traverse the random walks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed balance\n",
    "----------------\n",
    "$$\n",
    "\\pi(x_t) ~p(x_{t+1} \\mid x_t)\n",
    "= \\pi(x_{t+1}) ~p(x_t \\mid x_{t+1})\n",
    "$$\n",
    "the probability of moving from state $x_{t+1}$ to $x_{t}$\n",
    "is the same the other way around?\n",
    "\n",
    "integrate both sides wrt $x_t$, we have\n",
    "$$\n",
    "\\arrthree{\n",
    "\\int \\pi(x_t) ~p(x_{t+1} \\mid x_t) ~dx_t\n",
    "&=\n",
    "\\int \\pi(x_{t+1}) ~p(x_t \\mid x_{t+1}) ~dx_t\n",
    "\\\\\n",
    "&=\n",
    "\\pi(x_{t+1})\n",
    "}\n",
    "$$\n",
    "This is the continuous analogue of the steady state behaviour as mentioned before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metropolis-Hastings for logistic regression\n",
    "-------------------------------------------\n",
    "\n",
    "* target distribution: dist from which i want to sample  \n",
    "  * in bayesian inference, this is typically the posterior\n",
    "$$\n",
    "p(\\thetab \\mid \\Xb, \\yb) =\n",
    "\\frac{\n",
    "  \\prod_{i=1}^{t}\n",
    "    \\pi_i^{y_i} (1 -\\pi_i)^{1-y_i}\n",
    "  \\exp\n",
    "    \\left(\n",
    "      -\\frac{\\thetab^T \\thetab}\n",
    "            {2\\sigma^2}\n",
    "     \\right)\n",
    "}{\n",
    "Z}\n",
    "$$\n",
    "* first term is the bernoulli likelihood  \n",
    "* second term is the prior/ridge regularizer\n",
    "\n",
    "* in bayesian inference, once you specify the likelihood and the prior, you are fucking done. \n",
    "\n",
    "\n",
    "* we want samples $\\thetat{i} \\sim p(\\thetab \\mid \\Xb, \\yb)$\n",
    "  * if you have a representative sample set, then any integral can be approximated by a sample average.\n",
    "* for simplicity, denote $\\pi(x)$ = $p(\\thetab \\mid \\Xb, \\yb)$\n",
    "  * the goal becomes $\\xt{i} \\sim \\pi(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know the dist, not Z  \n",
    "$$\n",
    "\\pi(x) = \\fracone{Z} \\tilde{\\pi}(x)\n",
    "$$\n",
    "* $\\pi$: true prob density function\n",
    "* $\\tilde{\\pi}$: unnormalized density\n",
    "* $Z = \\int \\pi(x) ~dx$: unknown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm: MCMC:: Metropolis-Hastings\n",
    "----------------------------------------\n",
    "\n",
    "in bay inf, $\\xb$ are the parameters  \n",
    "$\\newcommand{\\mcmcthreshold}{\n",
    "\\text{min }\n",
    "\\left\\{\n",
    "1,\n",
    "\\frac{\n",
    "p(x^*) ~q(\\xt{i} \\mid x^*)\n",
    "}{\n",
    "p(\\xt{i}) ~q(x^* \\mid \\xt{i})\n",
    "}\n",
    "\\right\\}\n",
    "}$\n",
    "\n",
    "1. Initialize $\\xt{0}$\n",
    "1. for i=0 .. N-1\n",
    "  1. sample $u \\sim U_{[0,1]}$\n",
    "  1. sample $x^* \\sim q(x^* \\mid \\xt{i})$\n",
    "  1. if $u < A(\\xt{i}, x^*) = \\mcmcthreshold$\n",
    "    1. $\\xt{i+1} = x^*$\n",
    "  1. else\n",
    "    1. $\\xt{i+1} = \\xt{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i will ask you for an answer.  \n",
    "if it is really good, i will keep it.  \n",
    "else, i will keep the one i had previously.  \n",
    "if i am baffled, i will make a random decision.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $q(x^* \\mid \\xt{i})$: proposes a new $x^*$ given that you are in $\\xt{i}$    \n",
    "* for example,\n",
    "  * $x^* = \\xt{i} + \\mathcal{N}(0, \\sigma^2)$.\n",
    "  *That is, if you are in $\\xt{i}$, q will perturb the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* here $a = A(\\xt{i}, x^*)$ gives the closeness to the detailed balance.\n",
    "* what happens in the if condition is this:\n",
    "  * if $x^*$ is better than $\\xt{i}$, then ratio appreciates.\n",
    "  * the success is dependent on the interval [0,a].\n",
    "  * we randomly choose a $u \\sim U_{[0,1]}$.\n",
    "  * if a is close to one, the interval is long and there is a good chance that u will fall into it.\n",
    "  * that is, if a is close to 1, then there is a good chance i will choose it.\n",
    "  * that is, more a moves close to 1, higher is the chance it will be chosen.\n",
    "* q is there for rebalancing, which will be discussed below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the body of the for loop can be considered as a black box, which takes $\\xt{i}$ as the input and outputs $\\xt{i+1}$.\n",
    "* if an algorighm does that in a probabilistic way, then it is a conditional probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative method to find roots of a differentiable function\n",
    "f(x) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a sequence $\\{x_n\\}$ from initial guess $x_0$ converging to $x^*$ such that $f^{\\prime}(x^*) = 0$\n",
    "\n",
    "Second order taylor expansion $f_T(x)$ around $x_n$:\n",
    "$$\n",
    "f_T(x)\n",
    "=\n",
    "f_T(x_n+\\Delta x)\n",
    "\\approx\n",
    "f(x_n)+\n",
    "f'(x_n)\\Delta x+\n",
    "\\frac 1 2 f''(x_n) \\Delta x^2.\n",
    "$$\n",
    "\n",
    "We need to find $\\Delta x$ such that $f(x_n + \\Delta x)$ is max.\n",
    "That is. derivative of the last exp wrt $\\Delta x$ is zero.\n",
    "$$\n",
    "\\displaystyle 0 = \\frac{d}{d\\Delta x} \\left(f(x_n)+f'(x_n)\\Delta x+\\frac 1 2 f''(x_n) \\Delta x^2\\right) = f'(x_n)+f'' (x_n) \\Delta x.\n",
    "$$\n",
    "That is \n",
    "$$\n",
    "\\Delta x =\n",
    "\\frac\n",
    "{-f'(x_n)}\n",
    "{f''(x_n)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update equation\n",
    "=========\n",
    "$$\n",
    "x_{n+1} = \n",
    "x_n -\n",
    "\\frac\n",
    "{f'(x_n)}\n",
    "{f''(x_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Interpretation\n",
    "=============\n",
    "* at each iteration, approximate f(x) by a quadratic function around $x_n$\n",
    "* take a step towards the minima/maxima of that quadratic function\n",
    "* if f(x) is already a quadratic function, then optima is found in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher dimensions\n",
    "=========\n",
    "\n",
    "* Replace first derivative with $\\Delta f(x)$\n",
    "* Reciprocal of second derivative with inverse of Hessian $\\mathbf{H}$\n",
    "* That is,\n",
    "$$\n",
    "x_{n+1} = \n",
    "x_n - \n",
    "\\left[\n",
    "\\mathbf{H} f(x_n)\n",
    "\\right]^{-1}\n",
    "\\nabla f(x_n)\n",
    "$$\n",
    "* Including step size $\\gamma \\in (0,1)$\n",
    "$$\n",
    "x_{n+1} = \n",
    "x_n - \n",
    "\\gamma\n",
    "\\left[\n",
    "\\mathbf{H} f(x_n)\n",
    "\\right]^{-1}\n",
    "\\nabla f(x_n)\n",
    "$$\n",
    "  * done to ensure wolfe conditions are satisfied at each iteration\n",
    "* If $x_0$ is in nbrhd of local maximum, then convergence is quadratic.\n",
    "  * If Hessian is invertible and Lipschitz continuous function of x in nbrhd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hessian\n",
    "====\n",
    "\n",
    "* Finding H is expensive in high dim\n",
    "* calc vector $\\Delta x = x_{n+1} - x_n$ as solution to the system of linear equations\n",
    "$$\n",
    "\\left[\n",
    "\\mathbf{H} ~f(x_n)\n",
    "\\right]\n",
    "\\Delta x\n",
    "= -\\nabla f(x_n)\n",
    "$$\n",
    "* this is solved using iterative methods\n",
    "* but, cholesky factorization and conjugate gradient will work only if $\\left[\\mathbf{H} f(x_n)\\right]^{-1}$ is positive definite\n",
    "* Pos def is not a limitation but a sign that convergence is towards a saddle point, not a min."
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

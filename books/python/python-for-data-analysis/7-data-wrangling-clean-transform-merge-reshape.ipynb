{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "from graphviz import Digraph\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.polynomial as np_poly\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import random\n",
    "import scipy as sp\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DIR_HOME = os.environ['HOME']\n",
    "DIR_REPOS = DIR_HOME + \"/neo-human/repos\"\n",
    "DIR_BMLSP = DIR_REPOS + \"/luispedro/BuildingMachineLearningSystemsWithPython\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization\n",
    "$\n",
    "\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\Bracket}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\cases}[1]{\\begin{cases}#1\\end{cases}}\n",
    "\\newcommand{\\cov}[1]{\\text{cov} \\sigma\\left[#1\\right]}\n",
    "\\newcommand{\\diff}[2]{\\frac{d #1}{d #2}}\n",
    "\\newcommand{\\difftwo}[2]{\\frac{d^2 #1}{d {#2}^2}}\n",
    "\\newcommand{\\diffn}[2]{{#1}^{\\prime}(#2)}\n",
    "\\newcommand{\\ds}{\\displaystyle}\n",
    "\\newcommand{\\E}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\expb}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\EXP}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\frachalf}[1]{\\frac{#1}{2}~}\n",
    "\\newcommand{\\fracone}[1]{\\frac{1}{#1}~}\n",
    "\\newcommand{\\fracrec}[1]{\\frac{1}{#1}~}\n",
    "\\newcommand{\\half}{\\fracone{2}}\n",
    "\\newcommand{\\H}[1]{\\mathbb{H}\\left[#1\\right]}\n",
    "\\newcommand{\\Int}[2]{\\displaystyle \\int_{#1}^{#2}~}\n",
    "\\newcommand{\\intinfinf}{\\Int{-\\infty}{\\infty}}\n",
    "\\newcommand{\\inv}[1]{#1^{-1}}\n",
    "\\newcommand{\\invp}[1]{\\left({#1}\\right)^{-1}}\n",
    "\\newcommand{\\KL}[2]{\\text{KL}\\left(#1 \\Vert #2\\right)}\n",
    "\\newcommand{\\Lim}[1]{\\displaystyle \\lim_{#1}}\n",
    "\\newcommand{\\Ln}[1]{\\ln \\left\\(#1\\right\\)}\n",
    "\\newcommand{\\Lnb}[1]{\\ln \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\Mod}[1]{\\left|#1\\right|}\n",
    "\\newcommand{\\Norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\newcommand{\\Normsqr}[1]{\\Norm{#1}^2}\n",
    "\\newcommand{\\map}[1]{#1_{\\text{MAP}}}\n",
    "\\newcommand{\\ml}[1]{#1_{\\text{ML}}}\n",
    "\\newcommand{\\MI}[1]{\\mathcal{I}\\left(#1\\right)}\n",
    "\\newcommand{\\P}{\\mathbb{P}}\n",
    "\\newcommand{\\Paran}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\Partial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\sqrbrkt}[1]{\\Bracket{#1}^2}\n",
    "\\newcommand{\\sqrbrc}[1]{\\Brace{#1}^2}\n",
    "\\newcommand{\\trace}[1]{\\text{Tr}\\left( #1 \\right)}\n",
    "\\newcommand{\\traceb}[1]{\\text{Tr}\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\underl}[1]{\\text{$\\underline{#1}$}}\n",
    "\\newcommand{\\V}[1]{\\mathbb{V}\\left[#1\\right]}\n",
    "$\n",
    "$\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\mat}[1]{ \\left[ \\begin{matrix} #1 \\end{matrix} \\right] }\n",
    "\\newcommand{\\matp}[1]{ \\left( \\begin{matrix} #1 \\end{matrix} \\right)}\n",
    "\\newcommand{\\mats}[1]{ \\begin{matrix}#1\\end{matrix} }\n",
    "\\newcommand{\\arrthree}[1]{\n",
    "\\begin{array}{rlr} #1 \\end{array}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\Ca}{\\mathcal{C}}\n",
    "\\newcommand{\\Caone}{\\Ca_1}\n",
    "\\newcommand{\\Catwo}{\\Ca_2}\n",
    "\\newcommand{\\Cak}{\\Ca_k}\n",
    "\\newcommand{\\D}{\\mathcal{D}}\n",
    "\\newcommand{\\G}{\\mathcal{G}}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\L}{\\mathcal{L}}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\Ra}{\\mathcal{R}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\commentgray}[1]{\\color{gray}{\\text{#1}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum, product\n",
    "$\n",
    "\\newcommand{\\sumi}{\\displaystyle \\sum_i}\n",
    "\\newcommand{\\sumiD}{\\displaystyle \\sum_{i=1}^{D}}\n",
    "\\newcommand{\\sumiL}{\\displaystyle \\sum_{i=1}^{L}}\n",
    "\\newcommand{\\sumiN}{\\displaystyle \\sum_{i=1}^{N}}\n",
    "\\newcommand{\\sumjD}{\\displaystyle \\sum_{j=1}^{D}}\n",
    "\\newcommand{\\sumjK}{\\displaystyle \\sum_{j=1}^{K}}\n",
    "\\newcommand{\\sumjMl}{\\sum_{j=1}^{M-1}}\n",
    "\\newcommand{\\sumkK}{\\displaystyle \\sum_{k=1}^{K}}\n",
    "\\newcommand{\\sumkM}{\\displaystyle \\sum_{k=1}^{M}}\n",
    "\\newcommand{\\sumkMl}{\\sum_{k=1}^{M-1}}\n",
    "\\newcommand{\\sumkp}{\\displaystyle \\sum_{k=1}^{p}}\n",
    "\\newcommand{\\summN}{\\displaystyle \\sum_{m=1}^{N}}\n",
    "\\newcommand{\\sumnN}{\\displaystyle \\sum_{n=1}^{N}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\prodi}{\\displaystyle \\prod_i}\n",
    "\\newcommand{\\prodiD}{\\displaystyle \\prod_{i=1}^{D}}\n",
    "\\newcommand{\\prodiL}{\\displaystyle \\prod_{i=1}^{L}}\n",
    "\\newcommand{\\prodiN}{\\displaystyle \\prod_{i=1}^{N}}\n",
    "\\newcommand{\\prodjK}{\\displaystyle \\prod_{j=1}^{K}}\n",
    "\\newcommand{\\prodkK}{\\displaystyle \\prod_{k=1}^{K}}\n",
    "\\newcommand{\\prodmN}{\\displaystyle \\prod_{m=1}^{N}}\n",
    "\\newcommand{\\prodnN}{\\displaystyle \\prod_{n=1}^{N}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphabet shortcuts\n",
    "$\n",
    "\\newcommand{\\ab}{\\mathbf{a}}\n",
    "\\newcommand{\\at}{\\ab^T}\n",
    "\\newcommand{\\Ab}{\\mathbf{A}}\n",
    "\\newcommand{\\At}{\\Ab^T}\n",
    "\\newcommand{\\Ai}{\\inv{\\Ab}}\n",
    "\\newcommand{\\Abjk}{\\Ab_{jk}}\n",
    "\\newcommand{\\bb}{\\mathbf{b}}\n",
    "\\newcommand{\\bt}{\\bb^T}\n",
    "\\newcommand{\\Bb}{\\mathbf{B}}\n",
    "\\newcommand{\\Bt}{\\Bb^T}\n",
    "\\newcommand{\\Cb}{\\mathbf{C}}\n",
    "\\newcommand{\\Cn}{\\Cb_{N}}\n",
    "\\newcommand{\\Db}{\\mathbf{D}}\n",
    "\\newcommand{\\fb}{\\mathbf{f}}\n",
    "\\newcommand{\\fp}{f^{\\prime}}\n",
    "\\newcommand{\\Hb}{\\mathbf{H}}\n",
    "\\newcommand{\\hx}{h(\\xb)}\n",
    "\\newcommand{\\Jb}{\\mathbf{J}}\n",
    "\\newcommand{\\kb}{\\mathbf{k}}\n",
    "\\newcommand{\\kt}{\\kb^T}\n",
    "\\newcommand{\\Kb}{\\mathbf{K}}\n",
    "\\newcommand{\\Lb}{\\mathbf{L}}\n",
    "\\newcommand{\\Lt}{\\Lb^T}\n",
    "\\newcommand{\\Lbi}{\\Lb^{-1}}\n",
    "\\newcommand{\\mb}{\\mathbf{m}}\n",
    "\\newcommand{\\mt}{\\mb^T}\n",
    "\\newcommand{\\mbn}{\\mb_N}\n",
    "\\newcommand{\\mbnt}{\\mbn^T}\n",
    "\\newcommand{\\mbN}{\\mb_N}\n",
    "\\newcommand{\\mbNt}{\\mbn^T}\n",
    "\\newcommand{\\Mb}{\\mathbf{M}}\n",
    "\\newcommand{\\Qb}{\\mathbf{Q}}\n",
    "\\newcommand{\\Rb}{\\mathbf{R}}\n",
    "\\newcommand{\\sb}{\\mathbf{s}}\n",
    "\\newcommand{\\Sb}{\\mathbf{S}}\n",
    "\\newcommand{\\tb}{\\mathbf{t}}\n",
    "\\newcommand{\\tbnn}{\\tb_{N}}\n",
    "\\newcommand{\\tbnp}{\\tb_{N+1}}\n",
    "\\newcommand{\\tt}{\\tb^T}\n",
    "\\newcommand{\\Tb}{\\mathbf{T}}\n",
    "\\newcommand{\\Tt}{\\Tb^T}\n",
    "\\newcommand{\\ub}{\\mathbf{u}}\n",
    "\\newcommand{\\Ub}{\\mathbf{U}}\n",
    "\\newcommand{\\Ut}{\\Ub^T}\n",
    "\\newcommand{\\vb}{\\mathbf{v}}\n",
    "\\newcommand{\\Vb}{\\mathbf{V}}\n",
    "\\newcommand{\\wb}{\\mathbf{w}}\n",
    "\\newcommand{\\wnr}[1]{\\wb^{(\\text{#1})}}\n",
    "\\newcommand{\\wt}{\\wb^T}\n",
    "\\newcommand{\\Wb}{\\mathbf{W}}\n",
    "\\newcommand{\\Wt}{\\Wb^T}\n",
    "\\newcommand{\\Wtilde}{\\widetilde{\\Wb}}\n",
    "\\newcommand{\\Wtildet}{\\Wtilde^T}\n",
    "\\newcommand{\\Xb}{\\mathbf{X}}\n",
    "\\newcommand{\\Xt}{\\Xb^T}\n",
    "\\newcommand{\\Xk}{\\Xb_k}\n",
    "\\newcommand{\\Xkt}{\\Xk^T}\n",
    "\\newcommand{\\Xtilde}{\\widetilde{\\Xb}}\n",
    "\\newcommand{\\Xtildet}{\\Xtilde^T}\n",
    "\\newcommand{\\xb}{\\mathbf{x}}\n",
    "\\newcommand{\\xt}{\\xb^T}\n",
    "\\newcommand{\\xtilde}{\\widetilde{\\xb}}\n",
    "\\newcommand{\\xtilden}{\\xtilde_n}\n",
    "\\newcommand{\\xtildent}{\\xtilden^T}\n",
    "\\newcommand{\\xp}{x^{\\prime}}\n",
    "\\newcommand{\\xbp}{\\xb^{\\prime}}\n",
    "\\newcommand{\\xbm}{\\xb_m}\n",
    "\\newcommand{\\xbn}{\\xb_n}\n",
    "\\newcommand{\\xbnp}{\\xb_{N+1}}\n",
    "\\newcommand{\\xab}{\\mathbf{x_a}}\n",
    "\\newcommand{\\xabt}{\\mathbf{x_a}^T}\n",
    "\\newcommand{\\xbb}{\\mathbf{x_b}}\n",
    "\\newcommand{\\xbbt}{\\mathbf{x_b}^T}\n",
    "\\newcommand{\\yb}{\\mathbf{y}}\n",
    "\\newcommand{\\yt}{\\yb^T}\n",
    "\\newcommand{\\yx}{y(\\xb)}\n",
    "\\newcommand{\\Yb}{\\mathbf{Y}}\n",
    "\\newcommand{\\Yt}{\\Yb^T}\n",
    "\\newcommand{\\zb}{\\mathbf{z}}\n",
    "\\newcommand{\\zt}{\\zb^T}\n",
    "\\newcommand{\\zbm}{\\zb_m}\n",
    "\\newcommand{\\zbn}{\\zb_n}\n",
    "\\newcommand{\\zbnp}{\\zb_{n-1}}\n",
    "\\newcommand{\\znk}{\\zb_{nk}}\n",
    "\\newcommand{\\znpj}{\\zb_{n-1,j}}\n",
    "\\newcommand{\\Zb}{\\mathbf{Z}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math shortcuts\n",
    "$\n",
    "\\newcommand{\\alphab}{\\pmb{\\alpha}}\n",
    "\\newcommand{\\alphabt}{\\alphab^T}\n",
    "\\newcommand{\\betab}{\\pmb{\\beta}}\n",
    "\\newcommand{\\betabp}{\\betab^{\\prime}}\n",
    "\\newcommand{\\chib}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\etab}{\\pmb{\\eta}}\n",
    "\\newcommand{\\etabp}{\\etab^{\\prime}}\n",
    "\\newcommand{\\etat}{\\eta^T}\n",
    "\\newcommand{\\etabt}{\\etab^T}\n",
    "\\newcommand{\\Lambdab}{\\pmb{\\Lambda}}\n",
    "\\newcommand{\\laa}{\\Lambda_{aa}}\n",
    "\\newcommand{\\laai}{\\Lambda_{aa}^{-1}}\n",
    "\\newcommand{\\lab}{\\Lambda_{ab}}\n",
    "\\newcommand{\\lba}{\\Lambda_{ba}}\n",
    "\\newcommand{\\lbb}{\\Lambda_{bb}}\n",
    "\\newcommand{\\lbbi}{\\Lambda_{bb}^{-1}}\n",
    "\\newcommand{\\li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\Li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\mub}{\\pmb{\\mu}}\n",
    "\\newcommand{\\mut}{\\mub^T}\n",
    "\\newcommand{\\muab}{\\pmb{\\mu}_a}\n",
    "\\newcommand{\\mubb}{\\pmb{\\mu}_b}\n",
    "\\newcommand{\\Phib}{\\pmb{\\Phi}}\n",
    "\\newcommand{\\Phibt}{\\Phib^T}\n",
    "\\newcommand{\\pib}{\\pmb{\\pi}}\n",
    "\\newcommand{\\sigmasqr}{\\sigma^2}\n",
    "\\newcommand{\\saa}{\\Sigma_{aa}}\n",
    "\\newcommand{\\sab}{\\Sigma_{ab}}\n",
    "\\newcommand{\\sba}{\\Sigma_{ba}}\n",
    "\\newcommand{\\sbb}{\\Sigma_{bb}}\n",
    "\\newcommand{\\Sigmai}{\\inv{\\Sigma}}\n",
    "\\newcommand{\\thetab}{\\pmb{\\theta}}\n",
    "\\newcommand{\\thetat}{\\thetab^T}\n",
    "\\newcommand{\\thetabh}{\\hat{\\thetab}}\n",
    "\\newcommand{\\thetaold}{\\thetab^{\\text{old}}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\zerob}{\\pmb{0}}\n",
    "\\newcommand{\\oneb}{\\pmb{1}}\n",
    "\\newcommand{\\ed}{\\mathbb{E}_{\\D}}\n",
    "\\newcommand{\\edyx}{\\ed\\left[y(\\xb ; \\D)\\right]}\n",
    "\\newcommand{\\dx}{~dx}\n",
    "\\newcommand{\\dxb}{~d\\xb}\n",
    "\\newcommand{\\pxdxb}{p(\\xb) \\dxb}\n",
    "\\newcommand{\\dwb}{~d\\wb}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aliases for distributions\n",
    "$\\newcommand{\\multivarcoeff}{\\frac{1}{(2\\pi)^{D/2}}\n",
    "\\frac{1}{\\left| \\mathbf{\\Sigma}\\right|^{1/2}}}$\n",
    "$\\newcommand{\\multivarexp}[2]\n",
    "{\n",
    "\\left\\{\n",
    " -\\frac{1}{2} \n",
    " {#1}^T \n",
    " #2\n",
    " {#1}\n",
    "\\right\\}\n",
    "}$\n",
    "$\\newcommand{\\multivarexpx}[1]{\\multivarexp{#1}{\\Sigma^{-1}}}$\n",
    "$\\newcommand{\\multivarexpstd}{\\multivarexpx{(\\xb-\\mub)}}$\n",
    "$\\newcommand{\\gam}{\\operatorname{Gam}}$\n",
    "$\n",
    "\\newcommand{\\Nl}[3]{\\mathcal{N}\\left(#1 \\mid #2, #3\\right)}\n",
    "\\newcommand{\\Nstdx}{\\Nl{\\mathbf{x}}{\\mathbf{\\mu}}{\\Sigma}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<style>\"\\\n",
    "    \"div.cell{\"\\\n",
    "        \"width:100%;\"\\\n",
    "        \"margin-left:0%;\"\\\n",
    "        \"margin-right:auto;\"\\\n",
    "    \"}\"\\\n",
    "\"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining and merging data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## db style df merges"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],'data1': range(7)})\n",
    "df2 = DataFrame({'key': ['a', 'b', 'd'],'data2': range(3)})"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "`merge()` by default merges on the overlapping col names as merge-keys"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "specify join keys using \"on\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the column names are different in each object, you can specify them separately:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df3 = DataFrame({\n",
    "    'l_key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "    'data1': range(7)})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df4 = DataFrame({\n",
    "    'r_key': ['a', 'b', 'd'],\n",
    "    'data2': range(3)})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='l_key', right_on='r_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Notice that the keys, \"c\" in df3 and \"d\" in df4 have vanished. This is coz merge does an inner-join by default.\n",
    "\n",
    "arg-name: how\n",
    "possibles: inner, left, right, outer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='l_key', right_on='r_key', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many-to-many merges forms the cartesian product of matching rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge with multiple keys, pass a list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df_left = DataFrame({\n",
    "    'key1': ['foo', 'foo', 'bar'],\n",
    "    'key2': ['one', 'two', 'one'],\n",
    "    'lval': [1, 2, 3]})\n",
    "df_left"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df_right = DataFrame({\n",
    "    'key1': ['foo', 'foo', 'bar', 'bar'],\n",
    "    'key2': ['one', 'one', 'one', 'two'],\n",
    "    'rval': [4, 5, 6, 7]})\n",
    "df_right"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_left, df_right, on=['key1', 'key2'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlapping column names are handled by adding predetermined suffixes.  \n",
    "This is opposed to sql which adds table-name as a prefix.  \n",
    "\n",
    "Custom suffixes are specifies with `suffixes` arg"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.merge(df_left, df_right,\n",
    "         on='key1')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.merge(df_left, df_right,\n",
    "         on='key1', suffixes=('_l','_r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 7-1. merge function arguments\n",
    "\n",
    "| Argument | Description |\n",
    "| - | - |\n",
    "| left | DataFrame to be merged on the left side |\n",
    "| right | DataFrame to be merged on the right side |\n",
    "| how | One of 'inner', 'outer', 'left' or 'right' . 'inner' by default |\n",
    "| on | Column names to join on. Must be found in both DataFrame objects. If not specified and no other join keys given, will use the intersection of the column names in left and right as the join keys |\n",
    "| left_on | Columns in left DataFrame to use as join keys |\n",
    "| right_on | Analogous to left_on for left DataFrame |\n",
    "| left_index | Use row index in left as its join key (or keys, if a MultiIndex) |\n",
    "| right_index | Analogous to left_index |\n",
    "| sort | Sort merged data lexicographically by join keys; True by default. Disable to get better performance in some cases on large datasets |\n",
    "| suffixes | Tuple of string values to append to column names in case of overlap; defaults to ('_x', '_y') . For example, if 'data' in both DataFrame objects, would appear as 'data_x' and 'data_y' in result |\n",
    "| copy | If False , avoid copying data into resulting data structure in some exceptional cases. By default always copies |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging on index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using left_index, right_index args"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "left1 = DataFrame({\n",
    "    'key': ['a', 'b', 'a', 'a', 'b', 'c'],\n",
    "    'value': range(6)})\n",
    "left1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "right1 = DataFrame({'group_val': [3.5, 7]}, \n",
    "                   index=['a', 'b'])\n",
    "right1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is one-to-many, then the indices on the many side is retained"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.merge(left1, right1, \n",
    "         left_on='key',\n",
    "         right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    left1, right1,\n",
    "    left_on='key', right_index=True,\n",
    "    how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat along an axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, works like np concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy concat"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "arr1 = np.arange(12).reshape((3, 4))\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "np.concatenate([arr1, arr1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for series"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Series([0,1], index=['a','b'])\n",
    "s2 = Series([2,3,4], index=['c','d','e'])\n",
    "s3 = Series([5,6], index=['f','g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat works on axis=0 by default, producing a series.  \n",
    "if axis=1 is specified, a df is produced, with cols numbering from 0"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([s1,s2,s3])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([s1,s2,s3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = pd.concat([s1*5, s3])\n",
    "s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is outer join.   \n",
    "other joins can be specified."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hierarchical indexing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "result.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rem that concat with axis=1 produces df with cols numbered from 0.  \n",
    "this col numbering can be changed by specifying `keys` arg"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([s1,s2,s3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([s1,s2,s3], axis=1,\n",
    "         keys=['one','two','three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for df"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame(\n",
    "    np.arange(6).reshape(3, 2),\n",
    "    index=['a', 'b', 'c'],\n",
    "    columns=['one', 'two'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df2 = DataFrame(5 + np.arange(4).reshape(2, 2), \n",
    "                index=['a', 'c'],\n",
    "                columns=['three', 'four'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/o keys => normal index  \n",
    "w/ keys => hierarchical index"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, \n",
    "          keys=['level1', 'level2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "\n",
    "If you pass a dict of objects instead of a list, the dict’s keys will be used for the keys option    \n",
    "\n",
    "If names is passed, it will be assigned to the hierarchical indexing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat({'level1':df1, 'level2': df2}, \n",
    "          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, \n",
    "          keys=['level1', 'level2'],\n",
    "          names=['upper','lower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring iniices if not relevant"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame(\n",
    "    np.random.randn(3, 4),\n",
    "    columns=['a', 'b', 'c', 'd'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df2 = DataFrame(\n",
    "    np.random.randn(2, 3), \n",
    "    columns=['b', 'd', 'a'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 7-2. concat function arguments\n",
    "\n",
    "| Argument | Description |\n",
    "| - | - |\n",
    "| objs | List or dict of pandas objects to be concatenated. The only required argument |\n",
    "| axis | Axis to concatenate along; defaults to 0 |\n",
    "| join | One of 'inner', 'outer' , defaulting to 'outer' ; whether to intersection (inner) or union (outer) together indexes along the other axes |\n",
    "| join_axes | Specific indexes to use for the other n-1 axes instead of performing union/intersection logic |\n",
    "| keys | Values to associate with objects being concatenated, forming a hierarchical index along the concatenation axis. Can either be a list or array of arbitrary values, an array of tuples, or a list of arrays (if multiple level arrays passed in levels ) |\n",
    "| levels | Specific indexes to use as hierarchical index level or levels if keys passed |\n",
    "| names | Names for created hierarchical levels if keys and / or levels passed |\n",
    "| verify_integrity | Check new axis in concatenated object for duplicates and raise exception if so. By default ( False ) allows duplicates |\n",
    "| ignore_index | Do not preserve indexes along concatenation axis , instead producing a new range(total_length) index |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining data w/ overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine_First"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "a = Series(\n",
    "    [np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],\n",
    "    index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "b = Series(np.arange(len(a), dtype=np.float64),\n",
    "index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b[-1] = np.nan\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "np.where(pd.isnull(a),b,a)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "a.combine_first(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with df, its equivalent to patching the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame({\n",
    "    'a': [1., np.nan, 5., np.nan],\n",
    "    'b': [np.nan, 2., np.nan, 6.],\n",
    "    'c': range(2, 18, 4)})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df2 = DataFrame({\n",
    "    'a': [5., 4., np.nan, 3., 7.],\n",
    "    'b': [np.nan, 3., 4., 6., 8.]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only the NaN entries in df1 replaced with the corresponding ones from df2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping and pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshaping with hierarchical indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* stack : this “rotates” or pivots from the columns in the data to the rows\n",
    "* unstack : this pivots from the rows into the columns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(np.arange(6).reshape((2, 3)),\n",
    "index=pd.Index(['Ohio', 'Colorado'], name='state'),\n",
    "columns=pd.Index(['one', 'two', 'three'], name='number'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.stack()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.stack().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the innermost level is unstacked (same with stack ). You can unstack a different level by passing a level number or name:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.stack().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.stack().unstack('state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unstacking might introduce NaN's"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "s1 = Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "s2 = Series([4, 5, 6], index=['c', 'd', 'e'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data2 = pd.concat([s1, s2], keys=['one', 'two'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data2.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking filters out NaN's by default, which ofc can be overridden"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data2.unstack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data2.unstack().stack(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the level which gets stacked / unstacked  \n",
    "by default, the innermost -> innermost in either direction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(np.arange(6).reshape((2, 3)),\n",
    "index=pd.Index(['Ohio', 'Colorado'], name='state'),\n",
    "columns=pd.Index(['one', 'two', 'three'], name='number'))\n",
    "result = data.stack()\n",
    "df = DataFrame(\n",
    "    {'left': result, 'right': result + 5},\n",
    "    columns=pd.Index(['left', 'right'], name='side'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unstack: movies number from row to col"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df.unstack('state')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack('state').stack('side')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting from long to wide format"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "ldata = pd.read_csv('7-long-to-wide.csv',\n",
    "                    converters={\n",
    "                        'year': lambda x: int(float(x)),\n",
    "                        'quarter': lambda x: int(float(x))\n",
    "                    })\n",
    "ldata2 = ldata[['year','quarter','realgdp','infl','unemp']]\n",
    "ldata2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shitting way to data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_by_quarter = {1: '31', 2: '30', 3: '30', 4: '31'}\n",
    "days = [day_by_quarter[x] for x in ldata2['quarter'].values]\n",
    "m_d = zip(list(3*ldata2['quarter'].values),days)\n",
    "y_m_d = zip(ldata2['year'].values,m_d)\n",
    "days_of_our_lives = ['{0}-{1}-{2}'.format(x,y[0],y[1]) for x,y in y_m_d]\n",
    "days_of_our_lives[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sexy way of data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata2.apply(lambda r: \"{0}-{1}-{2}\".format(int(float(r[0])),int(r[1]*3),day_by_quarter[r[1]]), axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata3 = DataFrame({\n",
    "    'date': np.repeat(np.array(days_of_our_lives),3),\n",
    "    'value': ldata2.values[:,2:].ravel(),\n",
    "    'item': np.array(['realgdp','infl','unemp']*len(days_of_our_lives))},columns=['date','item', 'value'])\n",
    "ldata3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = ldata3.pivot('date','item','value')\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata3['value2'] = np.random.randn(len(ldata3))\n",
    "ldata3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "pivoted2 = ldata3.pivot('date','item')\n",
    "pivoted2.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "pivoted2['value'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pivot is just a shortcut for creating a hierarchical index using set_index and reshaping with unstack"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked = ldata3.set_index(['date','item']).unstack('item')\n",
    "unstacked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame({\n",
    "    'k1': ['one'] * 3 + ['two'] * 4,\n",
    "'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicates based on a column name"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(['k1'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(['k1'], take_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming using a function or mapping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data = DataFrame({\n",
    "    'food': ['bacon', 'pulled pork', 'bacon', \n",
    "             'Pastrami', 'corned beef', 'Bacon',\n",
    "             'pastrami', 'honey ham','nova lox'],\n",
    "    'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "meat_to_animal = {\n",
    "'bacon': 'pig',\n",
    "'pulled pork': 'pig',\n",
    "'pastrami': 'cow',\n",
    "'corned beef': 'cow',\n",
    "'honey ham': 'pig',\n",
    "'nova lox': 'salmon'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['animal'] = data['food'].map(str.lower).map(meat_to_animal)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['animal_2'] = data['food'].map(lambda x: meat_to_animal[str.lower(x)])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replacing values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data = Series([1., -999., 2., -999., -1000., 3.])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replacing multiple values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.replace([-999,-1000], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data.replace([-999,-1000],[np.nan,-1])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({-999: np.nan, -1000: -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replacing axis indexes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(np.arange(12).reshape((3, 4)),\n",
    "index=['Ohio', 'Colorado', 'New York'],\n",
    "columns=['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "like series, axis indices have a map function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.map(str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformed data w/o touching the original"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index = str.title, columns=str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with dict"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index={'Ohio': 'Indiana'}, columns={'three': 3, 'five': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to rename in place, set `inplace = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discretization and binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using pd.cut"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [18,25,35,60,100]\n",
    "cats = pd.cut(ages, bins)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "cats.labels"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "cats.categories"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default binning is left-open-right-closed.  \n",
    "this can be changed to left-closed-right-open by setting `right=False`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(ages,[18,26,36,61,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can pass bin names"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(ages, bins, labels=['Youth','Young Adult', 'Middle Aged', 'Senior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specifying number of bins"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(20)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cuts the range into 4 subranges"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(data, 4, precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get roughly equal size bins, use qcut"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "cats = pd.qcut(np.random.randn(100), 4)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specifying the bins for qcut"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(np.random.randn(100), [0, 0.1, 0.5, 0.8, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detecting and filtering outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "data = DataFrame(np.random.randn(1000,4))\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding values exceeding 3 in magnitude"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3][np.abs(data[3]) > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting rows having a value > 3 or -3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(np.abs(data)>3).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to cap values to [-3,3]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "data[(np.abs(data)>3)] = np.sign(data) * 3\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "the min and max values are now -3 and +3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permutation and random sampling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(np.arange(5*4).reshape(5,4))\n",
    "sampler = np.random.permutation(5)\n",
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df.take(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "sampling w/o replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "with replacement"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df.take(np.random.permutation(len(df))[:3])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df.take(np.random.randint(5))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(np.random.randint(0, len(df), size=len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing indicator/dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df = DataFrame({\n",
    "    'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n",
    "    'data1': range(6)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df['key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a prefix and joining"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(\n",
    "    df['key'], prefix='key')\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df.join(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple category shit"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnames = ['movie_id', 'title', 'genres']\n",
    "df_movies = pd.read_table('7-movies.dat', sep='::', header=None, names=mnames)\n",
    "df_movies[:3]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_arrs = movies['genres'].map(lambda x: x.split('|'))\n",
    "genre_arrs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sexy way to get unique genres"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = sorted(set.union(*(set(x) for x in genre_arrs)))\n",
    "genres[:5]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = DataFrame(np.zeros((len(genre_arrs),len(genres))), columns=genres, dtype=np.bool)\n",
    "for ix, mv_g in enumerate(genre_arrs):\n",
    "    df_genres.ix[ix, mv_g] = True\n",
    "df_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.join(df_genres.add_prefix('G_')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins and 1-of-K"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.random.rand(10)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(pd.cut(values, bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## string object methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 7-3. Python built-in string methods\n",
    "\n",
    "| Argument | Description |\n",
    "| - | - |\n",
    "| count | Return the number of non-overlapping occurrences of substring in the string. |\n",
    "| endswith, startswith | Returns True if string ends with suffix (starts with prefix). |\n",
    "| join | Use string as delimiter for concatenating a sequence of other strings. |\n",
    "| index | Return position of first character in substring if found in the string. Raises ValueError if not found. |\n",
    "| find | Return position of first character of first occurrence of substring in the string. Like index , but returns -1 if not found. |\n",
    "| rfind | Return position of first character of last occurrence of substring in the string. Returns -1 if not found. |\n",
    "| replace | Replace occurrences of string with another string. |\n",
    "| strip, rstrip, lstrip | Trim whitespace, including newlines; equivalent to x.strip() (and rstrip, lstrip , respectively) for each element. |\n",
    "| split | Break string into list of substrings using passed delimiter. |\n",
    "| lower, upper | Convert alphabet characters to lowercase or uppercase, respectively. |\n",
    "| ljust, rjust | Left justify or right justify, respectively. Pad opposite side of string with spaces (or some other fill character) to return a string with a minimum width. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 7-5. Vectorized string methods\n",
    "\n",
    "| Method | Description |\n",
    "| - | - |\n",
    "| cat | Concatenate strings element-wise with optional delimiter |\n",
    "| contains | Return boolean array if each string contains pattern/regex |\n",
    "| count | Count occurrences of pattern |\n",
    "| endswith, startswith | Equivalent to x.endswith(pattern) or x.startswith(pattern) for each element. |\n",
    "| findall | Compute list of all occurrences of pattern/regex for each string |\n",
    "| get | Index into each element (retrieve i-th element) |\n",
    "| join | Join strings in each element of the Series with passed separator |\n",
    "| len | Compute length of each string |\n",
    "| lower, upper | Convert cases; equivalent to x.lower() or x.upper() for each element. |\n",
    "| match | Use re.match with the passed regular expression on each element, returning matched groups as list. |\n",
    "| pad | Add whitespace to left, right, or both sides of strings |\n",
    "| center | Equivalent to pad(side='both') |\n",
    "| repeat | Duplicate values; for example s.str.repeat(3) equivalent to x * 3 for each string. |\n",
    "| replace | Replace occurrences of pattern/regex with some other string |\n",
    "| slice | Slice each string in the Series. |\n",
    "| split | Split strings on delimiter or regular expression |\n",
    "| strip, rstrip, lstrip | Trim whitespace, including newlines; equivalent to x.strip() (and rstrip, lstrip , respectively) for each element. |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "819px",
   "left": "0px",
   "right": "1128px",
   "top": "130px",
   "width": "117px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
